{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Experiments\n",
    "\n",
    "This week we will dive a bit deeper into GoogLeNet and ResNet, and implement versions of each. Both break with traditional convolutional nets. GoogLeNet uses \"parallel\" layers operating independently of each other that feed into the same output (inception modules).  ResNets feed information more than one layer forward "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MiniGoogLeNet\n",
    "\n",
    "Note for GoogLeNet, the inception modules are not exactly sequential, so we will need to define layers a little differently as we see below, after importing some packages. And, we use \"miniception\" modules as per *Understanding Deep Learning Requires Re-Thinking Generalization* (Zhang, et al., 2017 http://arxiv.org/abs/1611.03530), which work well for small-dimensional image datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import AveragePooling2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import concatenate\n",
    "from tensorflow.keras.layers import add\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.layers import add\n",
    "from tensorflow.keras import backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MiniGoogLeNet:\n",
    "    def convolution_module(x, K, kX, kY, stride, channelsDim, padding=\"same\"):\n",
    "        # create a CONV -> BN -> RELU sequence\n",
    "        x = Conv2D(K, (kX, kY), strides = stride, padding = padding)(x)\n",
    "        x = BatchNormalization(axis = channelsDim)(x)\n",
    "        x = Activation('relu')(x)\n",
    "        \n",
    "        # return the output\n",
    "        return x\n",
    "    \n",
    "    def inception_module(x, numberOf1x1Kernels, numberOf3x3Kernels, channelsDim):\n",
    "        # define two \"parallel\" convolutions of size 1x1 and 3x3 concatenated across the channels dimension\n",
    "        convolution_1x1 = MiniGoogLeNet.convolution_module(x, numberOf1x1Kernels, 1, 1, (1, 1), channelsDim)\n",
    "        convolution_3x3 = MiniGoogLeNet.convolution_module(x, numberOf3x3Kernels, 3, 3, (1, 1), channelsDim)\n",
    "        x = concatenate([convolution_1x1, convolution_3x3], axis = channelsDim)\n",
    "        \n",
    "        return x\n",
    "        \n",
    "    def downsample_module(x, K, channelsDim):\n",
    "        # define a CONV and POOL and then concatenate across the channels dimension\n",
    "        convolution_3x3 = MiniGoogLeNet.convolution_module(x, K, 3, 3, (2, 2), channelsDim, padding = 'valid')\n",
    "        pool = MaxPooling2D((3, 3), strides = (2, 2))(x)\n",
    "        x = concatenate([convolution_3x3, pool], axis = channelsDim)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def build(width, height, depth, classes):\n",
    "        inputShape = (height, width, depth)\n",
    "        channelsDim = -1\n",
    "        \n",
    "        if backend.image_data_format() == \"channels_first\":\n",
    "            inputShape = (depth, height, width)\n",
    "            channelsDim = 1\n",
    "        \n",
    "        # define the model input and first CONV module\n",
    "        inputs = Input(shape = inputShape)\n",
    "        x = MiniGoogLeNet.convolution_module(inputs, 96, 3, 3, (1, 1), channelsDim)\n",
    "        \n",
    "        # two inception modules followed by a downsample module\n",
    "        x = MiniGoogLeNet.inception_module(x, 32, 32, channelsDim)\n",
    "        x = MiniGoogLeNet.inception_module(x, 32, 48, channelsDim)\n",
    "        x = MiniGoogLeNet.downsample_module(x, 80, channelsDim)\n",
    "        \n",
    "        # four inception modules followed by a downsample module\n",
    "        x = MiniGoogLeNet.inception_module(x, 112, 48, channelsDim)\n",
    "        x = MiniGoogLeNet.inception_module(x, 96, 64, channelsDim)\n",
    "        x = MiniGoogLeNet.inception_module(x, 80, 80, channelsDim)\n",
    "        x = MiniGoogLeNet.inception_module(x, 48, 96, channelsDim)\n",
    "        x = MiniGoogLeNet.downsample_module(x, 96, channelsDim)\n",
    "        \n",
    "        # two inception modules followed by global POOL and dropout\n",
    "        x = MiniGoogLeNet.inception_module(x, 176, 160, channelsDim)\n",
    "        x = MiniGoogLeNet.inception_module(x, 176, 160, channelsDim)\n",
    "        x = AveragePooling2D((7, 7))(x)\n",
    "        x = Dropout(0.5)(x)\n",
    "        \n",
    "        # softmax classifier\n",
    "        x = Flatten()(x)\n",
    "        x = Dense(classes)(x)\n",
    "        x = Activation('softmax')(x)\n",
    "        \n",
    "        # create a model\n",
    "        model = Model(inputs, x, name='MiniGoogLeNet')\n",
    "        \n",
    "        # return the model\n",
    "        return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MiniGoogLeNet on CIFAR-10\n",
    "\n",
    "Let's test it on CIFAR-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] compiling model...\n",
      "Model: \"MiniGoogLeNet\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 32, 32, 96)   2688        input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 32, 32, 96)   384         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 32, 32, 96)   0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 32, 32, 32)   3104        activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 32, 32, 32)   27680       activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 32, 32, 32)   128         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 32, 32, 32)   128         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 32, 32, 32)   0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 32, 32, 32)   0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)    (None, 32, 32, 64)   0           activation_21[0][0]              \n",
      "                                                                 activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 32, 32, 32)   2080        concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 32, 32, 48)   27696       concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 32, 32, 32)   128         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 32, 32, 48)   192         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 32, 32, 32)   0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 32, 32, 48)   0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_11 (Concatenate)    (None, 32, 32, 80)   0           activation_23[0][0]              \n",
      "                                                                 activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 15, 15, 80)   57680       concatenate_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 15, 15, 80)   320         conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 15, 15, 80)   0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 15, 15, 80)   0           concatenate_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_12 (Concatenate)    (None, 15, 15, 160)  0           activation_25[0][0]              \n",
      "                                                                 max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 15, 15, 112)  18032       concatenate_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 15, 15, 48)   69168       concatenate_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 15, 15, 112)  448         conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 15, 15, 48)   192         conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 15, 15, 112)  0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 15, 15, 48)   0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_13 (Concatenate)    (None, 15, 15, 160)  0           activation_26[0][0]              \n",
      "                                                                 activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 15, 15, 96)   15456       concatenate_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 15, 15, 64)   92224       concatenate_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 15, 15, 96)   384         conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 15, 15, 64)   256         conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 15, 15, 96)   0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 15, 15, 64)   0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_14 (Concatenate)    (None, 15, 15, 160)  0           activation_28[0][0]              \n",
      "                                                                 activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 15, 15, 80)   12880       concatenate_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 15, 15, 80)   115280      concatenate_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 15, 15, 80)   320         conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 15, 15, 80)   320         conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 15, 15, 80)   0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 15, 15, 80)   0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_15 (Concatenate)    (None, 15, 15, 160)  0           activation_30[0][0]              \n",
      "                                                                 activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 15, 15, 48)   7728        concatenate_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 15, 15, 96)   138336      concatenate_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 15, 15, 48)   192         conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 15, 15, 96)   384         conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 15, 15, 48)   0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 15, 15, 96)   0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_16 (Concatenate)    (None, 15, 15, 144)  0           activation_32[0][0]              \n",
      "                                                                 activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 7, 7, 96)     124512      concatenate_16[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 7, 7, 96)     384         conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 7, 7, 96)     0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 7, 7, 144)    0           concatenate_16[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_17 (Concatenate)    (None, 7, 7, 240)    0           activation_34[0][0]              \n",
      "                                                                 max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 7, 7, 176)    42416       concatenate_17[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 7, 7, 160)    345760      concatenate_17[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 7, 7, 176)    704         conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 7, 7, 160)    640         conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 7, 7, 176)    0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 7, 7, 160)    0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_18 (Concatenate)    (None, 7, 7, 336)    0           activation_35[0][0]              \n",
      "                                                                 activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 7, 7, 176)    59312       concatenate_18[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 7, 7, 160)    484000      concatenate_18[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 7, 7, 176)    704         conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 7, 7, 160)    640         conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 7, 7, 176)    0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 7, 7, 160)    0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_19 (Concatenate)    (None, 7, 7, 336)    0           activation_37[0][0]              \n",
      "                                                                 activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 1, 1, 336)    0           concatenate_19[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 1, 1, 336)    0           average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 336)          0           dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 10)           3370        flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 10)           0           dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 1,656,250\n",
      "Trainable params: 1,652,826\n",
      "Non-trainable params: 3,424\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "[INFO] training network...\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/70\n",
      "50000/50000 [==============================] - 34s 672us/sample - loss: 1.3970 - accuracy: 0.4922 - val_loss: 1.2064 - val_accuracy: 0.5635\n",
      "Epoch 2/70\n",
      "50000/50000 [==============================] - 30s 606us/sample - loss: 0.9667 - accuracy: 0.6565 - val_loss: 0.8916 - val_accuracy: 0.6835\n",
      "Epoch 3/70\n",
      "50000/50000 [==============================] - 30s 602us/sample - loss: 0.7824 - accuracy: 0.7249 - val_loss: 1.4288 - val_accuracy: 0.5687\n",
      "Epoch 4/70\n",
      "50000/50000 [==============================] - 30s 604us/sample - loss: 0.6626 - accuracy: 0.7679 - val_loss: 0.8465 - val_accuracy: 0.7075\n",
      "Epoch 5/70\n",
      "50000/50000 [==============================] - 30s 605us/sample - loss: 0.5638 - accuracy: 0.8052 - val_loss: 1.1081 - val_accuracy: 0.6550\n",
      "Epoch 6/70\n",
      "50000/50000 [==============================] - 30s 606us/sample - loss: 0.4947 - accuracy: 0.8289 - val_loss: 0.7698 - val_accuracy: 0.7468\n",
      "Epoch 7/70\n",
      "50000/50000 [==============================] - 30s 606us/sample - loss: 0.4252 - accuracy: 0.8549 - val_loss: 0.9700 - val_accuracy: 0.7136\n",
      "Epoch 8/70\n",
      "50000/50000 [==============================] - 30s 606us/sample - loss: 0.3658 - accuracy: 0.8745 - val_loss: 0.6942 - val_accuracy: 0.7770\n",
      "Epoch 9/70\n",
      "50000/50000 [==============================] - 30s 607us/sample - loss: 0.3135 - accuracy: 0.8924 - val_loss: 0.6840 - val_accuracy: 0.7707\n",
      "Epoch 10/70\n",
      "50000/50000 [==============================] - 30s 606us/sample - loss: 0.2574 - accuracy: 0.9119 - val_loss: 0.7111 - val_accuracy: 0.7724\n",
      "Epoch 11/70\n",
      "50000/50000 [==============================] - 30s 610us/sample - loss: 0.2194 - accuracy: 0.9251 - val_loss: 0.7025 - val_accuracy: 0.7824\n",
      "Epoch 12/70\n",
      "50000/50000 [==============================] - 30s 600us/sample - loss: 0.1756 - accuracy: 0.9404 - val_loss: 0.7503 - val_accuracy: 0.7855\n",
      "Epoch 13/70\n",
      "50000/50000 [==============================] - 30s 599us/sample - loss: 0.1404 - accuracy: 0.9534 - val_loss: 0.9323 - val_accuracy: 0.7513\n",
      "Epoch 14/70\n",
      "50000/50000 [==============================] - 30s 598us/sample - loss: 0.1238 - accuracy: 0.9587 - val_loss: 0.7178 - val_accuracy: 0.7901\n",
      "Epoch 15/70\n",
      "50000/50000 [==============================] - 30s 600us/sample - loss: 0.0974 - accuracy: 0.9671 - val_loss: 0.9593 - val_accuracy: 0.7689\n",
      "Epoch 16/70\n",
      "50000/50000 [==============================] - 30s 608us/sample - loss: 0.0772 - accuracy: 0.9758 - val_loss: 0.7244 - val_accuracy: 0.8005\n",
      "Epoch 17/70\n",
      "50000/50000 [==============================] - 31s 624us/sample - loss: 0.0602 - accuracy: 0.9815 - val_loss: 0.8939 - val_accuracy: 0.7927\n",
      "Epoch 18/70\n",
      "50000/50000 [==============================] - 31s 612us/sample - loss: 0.0561 - accuracy: 0.9828 - val_loss: 1.1533 - val_accuracy: 0.7522\n",
      "Epoch 19/70\n",
      "50000/50000 [==============================] - 31s 613us/sample - loss: 0.0458 - accuracy: 0.9863 - val_loss: 0.9725 - val_accuracy: 0.7854\n",
      "Epoch 20/70\n",
      "50000/50000 [==============================] - 31s 615us/sample - loss: 0.0408 - accuracy: 0.9883 - val_loss: 1.1647 - val_accuracy: 0.7719\n",
      "Epoch 21/70\n",
      "50000/50000 [==============================] - 31s 615us/sample - loss: 0.0337 - accuracy: 0.9902 - val_loss: 0.7784 - val_accuracy: 0.8074\n",
      "Epoch 22/70\n",
      "50000/50000 [==============================] - 31s 616us/sample - loss: 0.0225 - accuracy: 0.9938 - val_loss: 0.7252 - val_accuracy: 0.8274\n",
      "Epoch 23/70\n",
      "50000/50000 [==============================] - 31s 614us/sample - loss: 0.0193 - accuracy: 0.9950 - val_loss: 0.7437 - val_accuracy: 0.8250\n",
      "Epoch 24/70\n",
      "50000/50000 [==============================] - 31s 615us/sample - loss: 0.0138 - accuracy: 0.9971 - val_loss: 0.7505 - val_accuracy: 0.8201\n",
      "Epoch 25/70\n",
      "50000/50000 [==============================] - 31s 622us/sample - loss: 0.0126 - accuracy: 0.9970 - val_loss: 0.7531 - val_accuracy: 0.8246\n",
      "Epoch 26/70\n",
      "50000/50000 [==============================] - 30s 606us/sample - loss: 0.0109 - accuracy: 0.9977 - val_loss: 0.7191 - val_accuracy: 0.8391\n",
      "Epoch 27/70\n",
      "50000/50000 [==============================] - 30s 602us/sample - loss: 0.0084 - accuracy: 0.9985 - val_loss: 0.7115 - val_accuracy: 0.8347\n",
      "Epoch 28/70\n",
      "50000/50000 [==============================] - 30s 600us/sample - loss: 0.0096 - accuracy: 0.9981 - val_loss: 0.8043 - val_accuracy: 0.8212\n",
      "Epoch 29/70\n",
      "50000/50000 [==============================] - 30s 600us/sample - loss: 0.0080 - accuracy: 0.9984 - val_loss: 0.9630 - val_accuracy: 0.8029\n",
      "Epoch 30/70\n",
      "50000/50000 [==============================] - 30s 601us/sample - loss: 0.0089 - accuracy: 0.9981 - val_loss: 0.7191 - val_accuracy: 0.8356\n",
      "Epoch 31/70\n",
      "50000/50000 [==============================] - 30s 603us/sample - loss: 0.0063 - accuracy: 0.9986 - val_loss: 0.7228 - val_accuracy: 0.8344\n",
      "Epoch 32/70\n",
      "50000/50000 [==============================] - 30s 601us/sample - loss: 0.0057 - accuracy: 0.9991 - val_loss: 0.8471 - val_accuracy: 0.8253\n",
      "Epoch 33/70\n",
      "50000/50000 [==============================] - 30s 603us/sample - loss: 0.0049 - accuracy: 0.9993 - val_loss: 0.7153 - val_accuracy: 0.8414\n",
      "Epoch 34/70\n",
      "50000/50000 [==============================] - 30s 603us/sample - loss: 0.0042 - accuracy: 0.9993 - val_loss: 0.7114 - val_accuracy: 0.8406\n",
      "Epoch 35/70\n",
      "50000/50000 [==============================] - 30s 603us/sample - loss: 0.0046 - accuracy: 0.9994 - val_loss: 0.7222 - val_accuracy: 0.8401\n",
      "Epoch 36/70\n",
      "50000/50000 [==============================] - 30s 604us/sample - loss: 0.0031 - accuracy: 0.9996 - val_loss: 0.7341 - val_accuracy: 0.8367\n",
      "Epoch 37/70\n",
      "50000/50000 [==============================] - 31s 615us/sample - loss: 0.0028 - accuracy: 0.9997 - val_loss: 0.7205 - val_accuracy: 0.8427\n",
      "Epoch 38/70\n",
      "50000/50000 [==============================] - 31s 618us/sample - loss: 0.0025 - accuracy: 0.9998 - val_loss: 0.7133 - val_accuracy: 0.8439\n",
      "Epoch 39/70\n",
      "50000/50000 [==============================] - 31s 616us/sample - loss: 0.0024 - accuracy: 0.9997 - val_loss: 0.7024 - val_accuracy: 0.8452\n",
      "Epoch 40/70\n",
      "50000/50000 [==============================] - 31s 616us/sample - loss: 0.0021 - accuracy: 0.9998 - val_loss: 0.7129 - val_accuracy: 0.8453\n",
      "Epoch 41/70\n",
      "50000/50000 [==============================] - 31s 616us/sample - loss: 0.0021 - accuracy: 0.9997 - val_loss: 0.7017 - val_accuracy: 0.8429\n",
      "Epoch 42/70\n",
      "50000/50000 [==============================] - 31s 614us/sample - loss: 0.0019 - accuracy: 0.9998 - val_loss: 0.7572 - val_accuracy: 0.8355\n",
      "Epoch 43/70\n",
      "50000/50000 [==============================] - 30s 605us/sample - loss: 0.0020 - accuracy: 0.9997 - val_loss: 0.7308 - val_accuracy: 0.8427\n",
      "Epoch 44/70\n",
      "50000/50000 [==============================] - 30s 604us/sample - loss: 0.0018 - accuracy: 0.9998 - val_loss: 0.7093 - val_accuracy: 0.8438\n",
      "Epoch 45/70\n",
      "50000/50000 [==============================] - 30s 606us/sample - loss: 0.0015 - accuracy: 0.9999 - val_loss: 0.7037 - val_accuracy: 0.8449\n",
      "Epoch 46/70\n",
      "50000/50000 [==============================] - 30s 604us/sample - loss: 0.0014 - accuracy: 0.9999 - val_loss: 0.7035 - val_accuracy: 0.8438\n",
      "Epoch 47/70\n",
      "50000/50000 [==============================] - 30s 605us/sample - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.7043 - val_accuracy: 0.8480\n",
      "Epoch 48/70\n",
      "50000/50000 [==============================] - 30s 604us/sample - loss: 0.0015 - accuracy: 0.9999 - val_loss: 0.7032 - val_accuracy: 0.8457\n",
      "Epoch 49/70\n",
      "50000/50000 [==============================] - 30s 606us/sample - loss: 0.0016 - accuracy: 0.9997 - val_loss: 0.7166 - val_accuracy: 0.8476\n",
      "Epoch 50/70\n",
      "50000/50000 [==============================] - 30s 605us/sample - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.7024 - val_accuracy: 0.8476\n",
      "Epoch 51/70\n",
      "50000/50000 [==============================] - 30s 608us/sample - loss: 0.0014 - accuracy: 0.9999 - val_loss: 0.7053 - val_accuracy: 0.8456\n",
      "Epoch 52/70\n",
      "50000/50000 [==============================] - 30s 605us/sample - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.7102 - val_accuracy: 0.8469\n",
      "Epoch 53/70\n",
      "50000/50000 [==============================] - 30s 605us/sample - loss: 0.0012 - accuracy: 0.9999 - val_loss: 0.7036 - val_accuracy: 0.8489\n",
      "Epoch 54/70\n",
      "50000/50000 [==============================] - 30s 606us/sample - loss: 0.0011 - accuracy: 0.9999 - val_loss: 0.7026 - val_accuracy: 0.8470\n",
      "Epoch 55/70\n",
      "50000/50000 [==============================] - 30s 605us/sample - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.7071 - val_accuracy: 0.8485\n",
      "Epoch 56/70\n",
      "50000/50000 [==============================] - 30s 606us/sample - loss: 0.0012 - accuracy: 0.9999 - val_loss: 0.7048 - val_accuracy: 0.8475\n",
      "Epoch 57/70\n",
      "50000/50000 [==============================] - 30s 606us/sample - loss: 0.0012 - accuracy: 0.9999 - val_loss: 0.7039 - val_accuracy: 0.8469\n",
      "Epoch 58/70\n",
      "50000/50000 [==============================] - 30s 606us/sample - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.7034 - val_accuracy: 0.8481\n",
      "Epoch 59/70\n",
      "50000/50000 [==============================] - 30s 606us/sample - loss: 9.4520e-04 - accuracy: 1.0000 - val_loss: 0.7033 - val_accuracy: 0.8470\n",
      "Epoch 60/70\n",
      "50000/50000 [==============================] - 30s 605us/sample - loss: 0.0010 - accuracy: 0.9999 - val_loss: 0.7057 - val_accuracy: 0.8482\n",
      "Epoch 61/70\n",
      "50000/50000 [==============================] - 31s 610us/sample - loss: 9.4762e-04 - accuracy: 1.0000 - val_loss: 0.7033 - val_accuracy: 0.8492\n",
      "Epoch 62/70\n",
      "50000/50000 [==============================] - 31s 620us/sample - loss: 9.8366e-04 - accuracy: 0.9999 - val_loss: 0.7021 - val_accuracy: 0.8485\n",
      "Epoch 63/70\n",
      "50000/50000 [==============================] - 31s 622us/sample - loss: 0.0010 - accuracy: 0.9999 - val_loss: 0.7011 - val_accuracy: 0.8490\n",
      "Epoch 64/70\n",
      "50000/50000 [==============================] - 31s 620us/sample - loss: 9.6195e-04 - accuracy: 0.9999 - val_loss: 0.7032 - val_accuracy: 0.8479\n",
      "Epoch 65/70\n",
      "50000/50000 [==============================] - 31s 621us/sample - loss: 8.5100e-04 - accuracy: 1.0000 - val_loss: 0.7035 - val_accuracy: 0.8482\n",
      "Epoch 66/70\n",
      "50000/50000 [==============================] - 164s 3ms/sample - loss: 9.8770e-04 - accuracy: 0.9999 - val_loss: 0.7044 - val_accuracy: 0.8487\n",
      "Epoch 67/70\n",
      "50000/50000 [==============================] - 594s 12ms/sample - loss: 8.8851e-04 - accuracy: 1.0000 - val_loss: 0.7035 - val_accuracy: 0.8476\n",
      "Epoch 68/70\n",
      "50000/50000 [==============================] - 590s 12ms/sample - loss: 7.9708e-04 - accuracy: 1.0000 - val_loss: 0.7045 - val_accuracy: 0.8473\n",
      "Epoch 69/70\n",
      "50000/50000 [==============================] - 590s 12ms/sample - loss: 9.4623e-04 - accuracy: 0.9999 - val_loss: 0.7031 - val_accuracy: 0.8481\n",
      "Epoch 70/70\n",
      "50000/50000 [==============================] - 589s 12ms/sample - loss: 9.3028e-04 - accuracy: 0.9999 - val_loss: 0.7031 - val_accuracy: 0.8476\n",
      "\n",
      " Test accuracy\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8530    0.8760    0.8643      1000\n",
      "           1     0.9294    0.9210    0.9252      1000\n",
      "           2     0.7956    0.7630    0.7790      1000\n",
      "           3     0.7381    0.7130    0.7253      1000\n",
      "           4     0.8097    0.8340    0.8217      1000\n",
      "           5     0.7885    0.7680    0.7781      1000\n",
      "           6     0.8674    0.8960    0.8815      1000\n",
      "           7     0.8657    0.8640    0.8649      1000\n",
      "           8     0.9207    0.9290    0.9248      1000\n",
      "           9     0.9003    0.9120    0.9061      1000\n",
      "\n",
      "    accuracy                         0.8476     10000\n",
      "   macro avg     0.8468    0.8476    0.8471     10000\n",
      "weighted avg     0.8468    0.8476    0.8471     10000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x19fea3d2248>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numberOfEpochs = 70\n",
    "initialLearningRate = 0.005\n",
    "\n",
    "def polynomial_decay(epoch):\n",
    "    maxEpochs = numberOfEpochs\n",
    "    baseLearningRate = initialLearningRate\n",
    "    power = 1.0\n",
    "    \n",
    "    alpha = baseLearningRate * (1 - (epoch / float(numberOfEpochs))) ** power\n",
    "    \n",
    "    # return the learning rate\n",
    "    return alpha\n",
    "    \n",
    "# load cifar10 data\n",
    "((trainX, trainY), (testX, testY)) = cifar10.load_data()\n",
    "trainX = trainX.astype('float')\n",
    "testX = testX.astype('float')\n",
    "\n",
    "# use mean subtraction\n",
    "mean = np.mean(trainX, axis = 0)\n",
    "trainX -= mean\n",
    "testX -= mean\n",
    "\n",
    "# convert labels to one-hot\n",
    "lb = LabelBinarizer()\n",
    "trainY = lb.fit_transform(trainY)\n",
    "testY = lb.transform(testY)\n",
    "\n",
    "callbacks = [LearningRateScheduler(polynomial_decay)]\n",
    "\n",
    "print('[INFO] compiling model...')\n",
    "opt = SGD(lr = initialLearningRate, momentum=0.9)\n",
    "model = MiniGoogLeNet.build(width = 32, height = 32, depth = 3, classes = 10)\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = opt, metrics=[\"accuracy\"])\n",
    "\n",
    "# print a model summary\n",
    "print(model.summary())\n",
    "\n",
    "# train the network\n",
    "print(\"[INFO] training network...\")\n",
    "H = model.fit(trainX, trainY, validation_data = (testX, testY), batch_size = 64, epochs = numberOfEpochs,\n",
    "              callbacks = callbacks, verbose = 1)\n",
    "\n",
    "# save the network to disk\n",
    "#print(\"[INFO] serializing network...\")\n",
    "#model.save('output/MiniGoogLeNet_cifar10.hdf5')\n",
    "\n",
    "# print a classification report\n",
    "print('\\n Test accuracy')\n",
    "predictedY = model.predict(testX)\n",
    "predictedY = predictedY.argmax(axis=1)\n",
    "testY = testY.argmax(axis=1)\n",
    "print(classification_report(testY, predictedY, digits=4))\n",
    "\n",
    "# plot the training loss and accuracy\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(np.arange(0, numberOfEpochs), H.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(np.arange(0, numberOfEpochs), H.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(np.arange(0, numberOfEpochs), H.history[\"accuracy\"], label=\"train_acc\")\n",
    "plt.plot(np.arange(0, numberOfEpochs), H.history[\"val_accuracy\"], label=\"val_acc\")\n",
    "plt.title(\"Training Loss and Accuracy\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This results in 85% accuracy, which is pretty good, but it seems to be overfitting.\n",
    "\n",
    "### GoogLeNet Experiment 2: Data Augmentation\n",
    "\n",
    "Let's see if data augmentation helps with the overfitting problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] compiling model...\n",
      "[INFO] training network...\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 781 steps, validate on 10000 samples\n",
      "Epoch 1/70\n",
      "781/781 [==============================] - 36s 46ms/step - loss: 1.4885 - accuracy: 0.4570 - val_loss: 1.3241 - val_accuracy: 0.5350\n",
      "Epoch 2/70\n",
      "781/781 [==============================] - 46s 58ms/step - loss: 1.0807 - accuracy: 0.6133 - val_loss: 1.0269 - val_accuracy: 0.6423\n",
      "Epoch 3/70\n",
      "781/781 [==============================] - 47s 60ms/step - loss: 0.8980 - accuracy: 0.6833 - val_loss: 1.2337 - val_accuracy: 0.5979\n",
      "Epoch 4/70\n",
      "781/781 [==============================] - 287s 368ms/step - loss: 0.7859 - accuracy: 0.7247 - val_loss: 0.8290 - val_accuracy: 0.7109\n",
      "Epoch 5/70\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.7043 - accuracy: 0.7562 - val_loss: 0.9168 - val_accuracy: 0.7040\n",
      "Epoch 6/70\n",
      "781/781 [==============================] - 32s 40ms/step - loss: 0.6400 - accuracy: 0.7788 - val_loss: 0.7356 - val_accuracy: 0.7498\n",
      "Epoch 7/70\n",
      "781/781 [==============================] - 32s 41ms/step - loss: 0.5908 - accuracy: 0.7991 - val_loss: 0.5919 - val_accuracy: 0.7986\n",
      "Epoch 8/70\n",
      "781/781 [==============================] - 31s 40ms/step - loss: 0.5529 - accuracy: 0.8102 - val_loss: 0.5287 - val_accuracy: 0.8157\n",
      "Epoch 9/70\n",
      "781/781 [==============================] - 32s 41ms/step - loss: 0.5130 - accuracy: 0.8233 - val_loss: 0.6551 - val_accuracy: 0.7804\n",
      "Epoch 10/70\n",
      "781/781 [==============================] - 32s 41ms/step - loss: 0.4841 - accuracy: 0.8326 - val_loss: 0.6248 - val_accuracy: 0.7923\n",
      "Epoch 11/70\n",
      "781/781 [==============================] - 34s 43ms/step - loss: 0.4549 - accuracy: 0.8442 - val_loss: 0.5544 - val_accuracy: 0.8125\n",
      "Epoch 12/70\n",
      "781/781 [==============================] - 33s 42ms/step - loss: 0.4276 - accuracy: 0.8539 - val_loss: 0.5215 - val_accuracy: 0.8232\n",
      "Epoch 13/70\n",
      "781/781 [==============================] - 32s 41ms/step - loss: 0.4073 - accuracy: 0.8597 - val_loss: 0.5667 - val_accuracy: 0.8098\n",
      "Epoch 14/70\n",
      "781/781 [==============================] - 33s 42ms/step - loss: 0.3831 - accuracy: 0.8684 - val_loss: 0.5344 - val_accuracy: 0.8280\n",
      "Epoch 15/70\n",
      "781/781 [==============================] - 33s 42ms/step - loss: 0.3667 - accuracy: 0.8748 - val_loss: 0.5955 - val_accuracy: 0.8113\n",
      "Epoch 16/70\n",
      "781/781 [==============================] - 33s 42ms/step - loss: 0.3534 - accuracy: 0.8791 - val_loss: 0.6372 - val_accuracy: 0.8000\n",
      "Epoch 17/70\n",
      "781/781 [==============================] - 32s 41ms/step - loss: 0.3360 - accuracy: 0.8840 - val_loss: 0.6217 - val_accuracy: 0.8066\n",
      "Epoch 18/70\n",
      "781/781 [==============================] - 32s 41ms/step - loss: 0.3153 - accuracy: 0.8925 - val_loss: 0.5073 - val_accuracy: 0.8415\n",
      "Epoch 19/70\n",
      "781/781 [==============================] - 34s 44ms/step - loss: 0.3081 - accuracy: 0.8948 - val_loss: 0.4990 - val_accuracy: 0.8434\n",
      "Epoch 20/70\n",
      "781/781 [==============================] - 33s 42ms/step - loss: 0.2899 - accuracy: 0.8992 - val_loss: 0.5315 - val_accuracy: 0.8339\n",
      "Epoch 21/70\n",
      "781/781 [==============================] - 33s 42ms/step - loss: 0.2787 - accuracy: 0.9030 - val_loss: 0.4541 - val_accuracy: 0.8515\n",
      "Epoch 22/70\n",
      "781/781 [==============================] - 33s 42ms/step - loss: 0.2674 - accuracy: 0.9073 - val_loss: 0.4498 - val_accuracy: 0.8575\n",
      "Epoch 23/70\n",
      "781/781 [==============================] - 33s 42ms/step - loss: 0.2540 - accuracy: 0.9121 - val_loss: 0.5526 - val_accuracy: 0.8261\n",
      "Epoch 24/70\n",
      "781/781 [==============================] - 32s 42ms/step - loss: 0.2431 - accuracy: 0.9150 - val_loss: 0.4986 - val_accuracy: 0.8536\n",
      "Epoch 25/70\n",
      "781/781 [==============================] - 33s 42ms/step - loss: 0.2363 - accuracy: 0.9183 - val_loss: 0.4999 - val_accuracy: 0.8404\n",
      "Epoch 26/70\n",
      "781/781 [==============================] - 32s 41ms/step - loss: 0.2239 - accuracy: 0.9226 - val_loss: 0.4601 - val_accuracy: 0.8543\n",
      "Epoch 27/70\n",
      "781/781 [==============================] - 32s 42ms/step - loss: 0.2147 - accuracy: 0.9248 - val_loss: 0.5616 - val_accuracy: 0.8415\n",
      "Epoch 28/70\n",
      "781/781 [==============================] - 32s 41ms/step - loss: 0.2069 - accuracy: 0.9281 - val_loss: 0.4426 - val_accuracy: 0.8612\n",
      "Epoch 29/70\n",
      "781/781 [==============================] - 32s 42ms/step - loss: 0.1963 - accuracy: 0.9323 - val_loss: 0.5748 - val_accuracy: 0.8440\n",
      "Epoch 30/70\n",
      "781/781 [==============================] - 31s 40ms/step - loss: 0.1866 - accuracy: 0.9357 - val_loss: 0.4577 - val_accuracy: 0.8625\n",
      "Epoch 31/70\n",
      "781/781 [==============================] - 33s 42ms/step - loss: 0.1815 - accuracy: 0.9374 - val_loss: 0.5142 - val_accuracy: 0.8529\n",
      "Epoch 32/70\n",
      "781/781 [==============================] - 33s 42ms/step - loss: 0.1769 - accuracy: 0.9389 - val_loss: 0.4344 - val_accuracy: 0.8674\n",
      "Epoch 33/70\n",
      "781/781 [==============================] - 33s 42ms/step - loss: 0.1655 - accuracy: 0.9417 - val_loss: 0.4369 - val_accuracy: 0.8662\n",
      "Epoch 34/70\n",
      "781/781 [==============================] - 32s 41ms/step - loss: 0.1560 - accuracy: 0.9451 - val_loss: 0.4728 - val_accuracy: 0.8643\n",
      "Epoch 35/70\n",
      "781/781 [==============================] - 33s 42ms/step - loss: 0.1526 - accuracy: 0.9470 - val_loss: 0.4316 - val_accuracy: 0.8724\n",
      "Epoch 36/70\n",
      "781/781 [==============================] - 32s 41ms/step - loss: 0.1472 - accuracy: 0.9494 - val_loss: 0.4312 - val_accuracy: 0.8726\n",
      "Epoch 37/70\n",
      "781/781 [==============================] - 32s 41ms/step - loss: 0.1364 - accuracy: 0.9522 - val_loss: 0.4678 - val_accuracy: 0.8695\n",
      "Epoch 38/70\n",
      "781/781 [==============================] - 32s 41ms/step - loss: 0.1315 - accuracy: 0.9554 - val_loss: 0.5301 - val_accuracy: 0.8546\n",
      "Epoch 39/70\n",
      "781/781 [==============================] - 32s 42ms/step - loss: 0.1243 - accuracy: 0.9578 - val_loss: 0.4176 - val_accuracy: 0.8806\n",
      "Epoch 40/70\n",
      "781/781 [==============================] - 33s 42ms/step - loss: 0.1194 - accuracy: 0.9590 - val_loss: 0.4525 - val_accuracy: 0.8776\n",
      "Epoch 41/70\n",
      "781/781 [==============================] - 34s 44ms/step - loss: 0.1143 - accuracy: 0.9614 - val_loss: 0.5994 - val_accuracy: 0.8495\n",
      "Epoch 42/70\n",
      "781/781 [==============================] - 32s 41ms/step - loss: 0.1117 - accuracy: 0.9627 - val_loss: 0.4881 - val_accuracy: 0.8687\n",
      "Epoch 43/70\n",
      "781/781 [==============================] - 33s 42ms/step - loss: 0.1097 - accuracy: 0.9625 - val_loss: 0.3934 - val_accuracy: 0.8863\n",
      "Epoch 44/70\n",
      "781/781 [==============================] - 32s 41ms/step - loss: 0.1015 - accuracy: 0.9647 - val_loss: 0.4375 - val_accuracy: 0.8785\n",
      "Epoch 45/70\n",
      "781/781 [==============================] - 33s 43ms/step - loss: 0.0976 - accuracy: 0.9670 - val_loss: 0.4390 - val_accuracy: 0.8770\n",
      "Epoch 46/70\n",
      "781/781 [==============================] - 32s 41ms/step - loss: 0.0939 - accuracy: 0.9678 - val_loss: 0.4563 - val_accuracy: 0.8787\n",
      "Epoch 47/70\n",
      "781/781 [==============================] - 32s 41ms/step - loss: 0.0885 - accuracy: 0.9698 - val_loss: 0.4204 - val_accuracy: 0.8897\n",
      "Epoch 48/70\n",
      "781/781 [==============================] - 33s 42ms/step - loss: 0.0842 - accuracy: 0.9718 - val_loss: 0.4635 - val_accuracy: 0.8767\n",
      "Epoch 49/70\n",
      "781/781 [==============================] - 32s 42ms/step - loss: 0.0792 - accuracy: 0.9736 - val_loss: 0.4152 - val_accuracy: 0.8829\n",
      "Epoch 50/70\n",
      "781/781 [==============================] - 32s 41ms/step - loss: 0.0759 - accuracy: 0.9750 - val_loss: 0.4024 - val_accuracy: 0.8933\n",
      "Epoch 51/70\n",
      "781/781 [==============================] - 33s 42ms/step - loss: 0.0725 - accuracy: 0.9769 - val_loss: 0.4077 - val_accuracy: 0.8898\n",
      "Epoch 52/70\n",
      "781/781 [==============================] - 33s 42ms/step - loss: 0.0672 - accuracy: 0.9776 - val_loss: 0.4944 - val_accuracy: 0.8753\n",
      "Epoch 53/70\n",
      "781/781 [==============================] - 33s 42ms/step - loss: 0.0631 - accuracy: 0.9795 - val_loss: 0.4167 - val_accuracy: 0.8892\n",
      "Epoch 54/70\n",
      "781/781 [==============================] - 33s 42ms/step - loss: 0.0607 - accuracy: 0.9798 - val_loss: 0.4305 - val_accuracy: 0.8898\n",
      "Epoch 55/70\n",
      "781/781 [==============================] - 32s 41ms/step - loss: 0.0590 - accuracy: 0.9807 - val_loss: 0.4301 - val_accuracy: 0.8892\n",
      "Epoch 56/70\n",
      "781/781 [==============================] - 32s 41ms/step - loss: 0.0553 - accuracy: 0.9826 - val_loss: 0.4199 - val_accuracy: 0.8899\n",
      "Epoch 57/70\n",
      "781/781 [==============================] - 32s 41ms/step - loss: 0.0556 - accuracy: 0.9818 - val_loss: 0.4213 - val_accuracy: 0.8912\n",
      "Epoch 58/70\n",
      "781/781 [==============================] - 32s 42ms/step - loss: 0.0517 - accuracy: 0.9835 - val_loss: 0.4138 - val_accuracy: 0.8947\n",
      "Epoch 59/70\n",
      "781/781 [==============================] - 32s 41ms/step - loss: 0.0494 - accuracy: 0.9846 - val_loss: 0.4567 - val_accuracy: 0.8897\n",
      "Epoch 60/70\n",
      "781/781 [==============================] - 32s 40ms/step - loss: 0.0468 - accuracy: 0.9857 - val_loss: 0.4122 - val_accuracy: 0.8963\n",
      "Epoch 61/70\n",
      "781/781 [==============================] - 34s 43ms/step - loss: 0.0463 - accuracy: 0.9859 - val_loss: 0.4152 - val_accuracy: 0.8957\n",
      "Epoch 62/70\n",
      "781/781 [==============================] - 33s 43ms/step - loss: 0.0439 - accuracy: 0.9866 - val_loss: 0.4077 - val_accuracy: 0.8968\n",
      "Epoch 63/70\n",
      "781/781 [==============================] - 32s 41ms/step - loss: 0.0414 - accuracy: 0.9875 - val_loss: 0.4042 - val_accuracy: 0.8991\n",
      "Epoch 64/70\n",
      "781/781 [==============================] - 33s 42ms/step - loss: 0.0407 - accuracy: 0.9881 - val_loss: 0.4034 - val_accuracy: 0.8973\n",
      "Epoch 65/70\n",
      "781/781 [==============================] - 33s 42ms/step - loss: 0.0384 - accuracy: 0.9883 - val_loss: 0.3911 - val_accuracy: 0.8988\n",
      "Epoch 66/70\n",
      "781/781 [==============================] - 33s 42ms/step - loss: 0.0379 - accuracy: 0.9889 - val_loss: 0.4021 - val_accuracy: 0.8981\n",
      "Epoch 67/70\n",
      "781/781 [==============================] - 32s 42ms/step - loss: 0.0353 - accuracy: 0.9900 - val_loss: 0.3929 - val_accuracy: 0.8994\n",
      "Epoch 68/70\n",
      "781/781 [==============================] - 32s 41ms/step - loss: 0.0344 - accuracy: 0.9906 - val_loss: 0.3970 - val_accuracy: 0.8993\n",
      "Epoch 69/70\n",
      "781/781 [==============================] - 33s 42ms/step - loss: 0.0348 - accuracy: 0.9906 - val_loss: 0.3961 - val_accuracy: 0.9005\n",
      "Epoch 70/70\n",
      "781/781 [==============================] - 33s 42ms/step - loss: 0.0328 - accuracy: 0.9906 - val_loss: 0.3952 - val_accuracy: 0.8995\n",
      "Model: \"MiniGoogLeNet\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 32, 32, 96)   2688        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 32, 32, 96)   384         conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 32, 32, 96)   0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 32, 32, 32)   3104        activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 32, 32, 32)   27680       activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 32, 32, 32)   128         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 32, 32, 32)   128         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 32, 32, 32)   0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 32, 32, 32)   0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 32, 32, 64)   0           activation_1[0][0]               \n",
      "                                                                 activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 32, 32, 32)   2080        concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 32, 32, 48)   27696       concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 32, 32, 32)   128         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 32, 32, 48)   192         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 32, 32, 32)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 32, 32, 48)   0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 32, 32, 80)   0           activation_3[0][0]               \n",
      "                                                                 activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 15, 15, 80)   57680       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 15, 15, 80)   320         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 15, 15, 80)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 15, 15, 80)   0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 15, 15, 160)  0           activation_5[0][0]               \n",
      "                                                                 max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 15, 15, 112)  18032       concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 15, 15, 48)   69168       concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 15, 15, 112)  448         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 15, 15, 48)   192         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 15, 15, 112)  0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 15, 15, 48)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 15, 15, 160)  0           activation_6[0][0]               \n",
      "                                                                 activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 15, 15, 96)   15456       concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 15, 15, 64)   92224       concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 15, 15, 96)   384         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 15, 15, 64)   256         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 15, 15, 96)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 15, 15, 64)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 15, 15, 160)  0           activation_8[0][0]               \n",
      "                                                                 activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 15, 15, 80)   12880       concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 15, 15, 80)   115280      concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 15, 15, 80)   320         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 15, 15, 80)   320         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 15, 15, 80)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 15, 15, 80)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 15, 15, 160)  0           activation_10[0][0]              \n",
      "                                                                 activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 15, 15, 48)   7728        concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 15, 15, 96)   138336      concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 15, 15, 48)   192         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 15, 15, 96)   384         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 15, 15, 48)   0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 15, 15, 96)   0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 15, 15, 144)  0           activation_12[0][0]              \n",
      "                                                                 activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 7, 7, 96)     124512      concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 7, 7, 96)     384         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 7, 7, 96)     0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 7, 7, 144)    0           concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 7, 7, 240)    0           activation_14[0][0]              \n",
      "                                                                 max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 7, 7, 176)    42416       concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 7, 7, 160)    345760      concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 7, 7, 176)    704         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 7, 7, 160)    640         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 7, 7, 176)    0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 7, 7, 160)    0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 7, 7, 336)    0           activation_15[0][0]              \n",
      "                                                                 activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 7, 7, 176)    59312       concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 7, 7, 160)    484000      concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 7, 7, 176)    704         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 7, 7, 160)    640         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 7, 7, 176)    0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 7, 7, 160)    0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, 7, 7, 336)    0           activation_17[0][0]              \n",
      "                                                                 activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d (AveragePooli (None, 1, 1, 336)    0           concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 1, 1, 336)    0           average_pooling2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 336)          0           dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 10)           3370        flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 10)           0           dense[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 1,656,250\n",
      "Trainable params: 1,652,826\n",
      "Non-trainable params: 3,424\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "\n",
      " Test accuracy\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8994    0.9300    0.9145      1000\n",
      "           1     0.9412    0.9610    0.9510      1000\n",
      "           2     0.8774    0.8660    0.8717      1000\n",
      "           3     0.8148    0.7920    0.8032      1000\n",
      "           4     0.8807    0.8860    0.8833      1000\n",
      "           5     0.8582    0.8410    0.8495      1000\n",
      "           6     0.9097    0.9470    0.9280      1000\n",
      "           7     0.9251    0.9010    0.9129      1000\n",
      "           8     0.9540    0.9340    0.9439      1000\n",
      "           9     0.9314    0.9370    0.9342      1000\n",
      "\n",
      "    accuracy                         0.8995     10000\n",
      "   macro avg     0.8992    0.8995    0.8992     10000\n",
      "weighted avg     0.8992    0.8995    0.8992     10000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x19311623748>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numberOfEpochs = 70\n",
    "initialLearningRate = 0.005\n",
    "\n",
    "def polynomial_decay(epoch):\n",
    "    maxEpochs = numberOfEpochs\n",
    "    baseLearningRate = initialLearningRate\n",
    "    power = 1.0\n",
    "    \n",
    "    alpha = baseLearningRate * (1 - (epoch / float(numberOfEpochs))) ** power\n",
    "    \n",
    "    # return the learning rate\n",
    "    return alpha\n",
    "    \n",
    "# load cifar10 data\n",
    "((trainX, trainY), (testX, testY)) = cifar10.load_data()\n",
    "trainX = trainX.astype('float')\n",
    "testX = testX.astype('float')\n",
    "\n",
    "# use mean subtraction\n",
    "mean = np.mean(trainX, axis = 0)\n",
    "trainX -= mean\n",
    "testX -= mean\n",
    "\n",
    "# convert labels to one-hot\n",
    "lb = LabelBinarizer()\n",
    "trainY = lb.fit_transform(trainY)\n",
    "testY = lb.transform(testY)\n",
    "\n",
    "# construct the image generator for data augmentation\n",
    "aug = ImageDataGenerator(width_shift_range = 0.1, height_shift_range = 0.1,\n",
    "                         horizontal_flip = True, fill_mode=\"nearest\")\n",
    "\n",
    "callbacks = [LearningRateScheduler(polynomial_decay)]\n",
    "\n",
    "print('[INFO] compiling model...')\n",
    "opt = SGD(lr = initialLearningRate, momentum=0.9)\n",
    "model = MiniGoogLeNet.build(width = 32, height = 32, depth = 3, classes = 10)\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = opt, metrics=[\"accuracy\"])\n",
    "\n",
    "# train the network\n",
    "print(\"[INFO] training network...\")\n",
    "\n",
    "H = model.fit(aug.flow(trainX, trainY, batch_size=64), validation_data=(testX, testY),\n",
    "              steps_per_epoch=len(trainX) // 64, epochs=numberOfEpochs, callbacks = callbacks, verbose=1)\n",
    "\n",
    "# print a model summary\n",
    "print(model.summary())\n",
    "\n",
    "# print a classification report\n",
    "print('\\n Test accuracy')\n",
    "predictedY = model.predict(testX)\n",
    "predictedY = predictedY.argmax(axis=1)\n",
    "testY = testY.argmax(axis=1)\n",
    "print(classification_report(testY, predictedY, digits=4))\n",
    "\n",
    "# plot the training loss and accuracy\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(np.arange(0, numberOfEpochs), H.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(np.arange(0, numberOfEpochs), H.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(np.arange(0, numberOfEpochs), H.history[\"accuracy\"], label=\"train_acc\")\n",
    "plt.plot(np.arange(0, numberOfEpochs), H.history[\"val_accuracy\"], label=\"val_acc\")\n",
    "plt.title(\"Training Loss and Accuracy\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've now cracked 90% for the first time with CIFAR-10!\n",
    "\n",
    "## ResNet\n",
    "\n",
    "Let's implement a ResNet next. We will write a function to create residual modules first and then iteratively construct the architecture to save some repetition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet:\n",
    "    def residual_module(data, K, stride, channelsDim, reduce = False, reg = 0.0001, bnEpsilon = 0.00002, bnMomentum = 0.9):\n",
    "        shortcut = data\n",
    "        \n",
    "        # 1x1 CONVs\n",
    "        bn1 = BatchNormalization(axis = channelsDim, epsilon = bnEpsilon, momentum = bnMomentum)(data)\n",
    "        act1 = Activation('relu')(bn1)\n",
    "        conv1 = Conv2D(int(K * 0.25), (1, 1), use_bias = False, kernel_regularizer = l2(reg))(act1)\n",
    "        \n",
    "        # 3x3 CONVs\n",
    "        bn2 = BatchNormalization(axis = channelsDim, epsilon = bnEpsilon, momentum = bnMomentum)(conv1)\n",
    "        act2 = Activation('relu')(bn2)\n",
    "        conv2 = Conv2D(int(K * 0.25), (3, 3), strides = stride, padding = 'same', use_bias = False, kernel_regularizer = l2(reg))(act2)\n",
    "        \n",
    "        # 1x1 CONVs\n",
    "        bn3 = BatchNormalization(axis = channelsDim, epsilon = bnEpsilon, momentum = bnMomentum)(conv2)\n",
    "        act3 = Activation('relu')(bn3)\n",
    "        conv3 = Conv2D(K, (1, 1), use_bias = False, kernel_regularizer = l2(reg))(act3)\n",
    "        \n",
    "        # if we reduce the spatial size, apply a CONV layer to the shortcut\n",
    "        if reduce:\n",
    "            shortcut = Conv2D(K, (1, 1), strides = stride, use_bias = False, kernel_regularizer = l2(reg))(act1)\n",
    "            \n",
    "        # add the shortcut and the final CONV\n",
    "        x = add([conv3, shortcut])\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def build(width, height, depth, classes, stages, filters, reg = 0.0001, bnEpsilon = 0.00002, bnMomentum = 0.9, dataset='cifar'):\n",
    "        inputShape = (height, width, depth)\n",
    "        channelsDim = -1\n",
    "        \n",
    "        if backend.image_data_format() == 'channels_first':\n",
    "            inputShape = (depth, height, width)\n",
    "            channelsDim = 1\n",
    "            \n",
    "        # set the input and apply BN\n",
    "        inputs = Input(shape = inputShape)\n",
    "        x = BatchNormalization(axis = channelsDim, epsilon = bnEpsilon, momentum = bnMomentum)(inputs)\n",
    "        \n",
    "        if dataset == 'cifar':\n",
    "            # apply a single CONV layer\n",
    "            x = Conv2D(filters[0], (3, 3), use_bias = False, padding = 'same',\n",
    "                       kernel_regularizer = l2(reg))(x)\n",
    "        \n",
    "        # loop over the number of stages\n",
    "        for counter in range(0, len(stages)):\n",
    "            # initialize the stride\n",
    "            if counter == 0:\n",
    "                stride = (1, 1)\n",
    "            else:\n",
    "                stride = (2, 2)\n",
    "                    \n",
    "            # apply a residual module to reduce the spatial dimension of the image volume\n",
    "            x = ResNet.residual_module(x, filters[counter + 1], stride, channelsDim, reduce = True, bnEpsilon = bnEpsilon, bnMomentum = bnMomentum)\n",
    "            \n",
    "            # loop over the number of layers in the current stage\n",
    "            for j in range(0, stages[counter] - 1):\n",
    "                # apply a residual module\n",
    "                x = ResNet.residual_module(x, filters[counter + 1], (1, 1), channelsDim, bnEpsilon = bnEpsilon, bnMomentum = bnMomentum)\n",
    "                    \n",
    "        # apply BN -> ACT -> POOL\n",
    "        x = BatchNormalization(axis = channelsDim, epsilon = bnEpsilon, momentum = bnMomentum)(x)\n",
    "        x = Activation('relu')(x)\n",
    "        x = AveragePooling2D((8, 8))(x)\n",
    "        \n",
    "        # softmax classifier\n",
    "        x = Flatten()(x)\n",
    "        x = Dense(classes, kernel_regularizer = l2(reg))(x)\n",
    "        x = Activation('softmax')(x)\n",
    "        \n",
    "        # create the model\n",
    "        model = Model(inputs, x, name = 'ResNet')\n",
    "        \n",
    "        # return the model\n",
    "        return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResNet on CIFAR-10\n",
    "\n",
    "Let's test it on CIFAR-10, this time with data augmentation from the start."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading CIFAR-10 data...\n",
      "[INFO] compiling model...\n",
      "Model: \"ResNet\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 32, 32, 3)    12          input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 32, 32, 64)   1728        batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 32, 32, 64)   256         conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 32, 32, 64)   0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 32, 32, 16)   1024        activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 32, 32, 16)   64          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 32, 32, 16)   0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 32, 32, 16)   2304        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 32, 32, 16)   64          conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 32, 32, 16)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 32, 32, 64)   1024        activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 32, 32, 64)   4096        activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 32, 32, 64)   0           conv2d_3[0][0]                   \n",
      "                                                                 conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 32, 32, 64)   256         add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 32, 32, 64)   0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 32, 32, 16)   1024        activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 32, 32, 16)   64          conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 32, 32, 16)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 32, 32, 16)   2304        activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 32, 32, 16)   64          conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 32, 32, 16)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 32, 32, 64)   1024        activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 32, 32, 64)   0           conv2d_7[0][0]                   \n",
      "                                                                 add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 32, 32, 64)   256         add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 32, 32, 64)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 32, 32, 16)   1024        activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 32, 32, 16)   64          conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 32, 32, 16)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 32, 32, 16)   2304        activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 32, 32, 16)   64          conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 32, 32, 16)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 32, 32, 64)   1024        activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 32, 32, 64)   0           conv2d_10[0][0]                  \n",
      "                                                                 add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 32, 32, 64)   256         add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 32, 32, 64)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 32, 32, 16)   1024        activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 32, 32, 16)   64          conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 32, 32, 16)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 32, 32, 16)   2304        activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 32, 32, 16)   64          conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 32, 32, 16)   0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 32, 32, 64)   1024        activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 32, 32, 64)   0           conv2d_13[0][0]                  \n",
      "                                                                 add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 32, 32, 64)   256         add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 32, 32, 64)   0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 32, 32, 16)   1024        activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 32, 32, 16)   64          conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 32, 32, 16)   0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 32, 32, 16)   2304        activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 32, 32, 16)   64          conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 32, 32, 16)   0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 32, 32, 64)   1024        activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 32, 32, 64)   0           conv2d_16[0][0]                  \n",
      "                                                                 add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 32, 32, 64)   256         add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 32, 32, 64)   0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 32, 32, 16)   1024        activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 32, 32, 16)   64          conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 32, 32, 16)   0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 32, 32, 16)   2304        activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 32, 32, 16)   64          conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 32, 32, 16)   0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 32, 32, 64)   1024        activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 32, 32, 64)   0           conv2d_19[0][0]                  \n",
      "                                                                 add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 32, 32, 64)   256         add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 32, 32, 64)   0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 32, 32, 16)   1024        activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 32, 32, 16)   64          conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 32, 32, 16)   0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 32, 32, 16)   2304        activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 32, 32, 16)   64          conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 32, 32, 16)   0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 32, 32, 64)   1024        activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 32, 32, 64)   0           conv2d_22[0][0]                  \n",
      "                                                                 add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 32, 32, 64)   256         add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 32, 32, 64)   0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 32, 32, 16)   1024        activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 32, 32, 16)   64          conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 32, 32, 16)   0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 32, 32, 16)   2304        activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 32, 32, 16)   64          conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 32, 32, 16)   0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 32, 32, 64)   1024        activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 32, 32, 64)   0           conv2d_25[0][0]                  \n",
      "                                                                 add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 32, 32, 64)   256         add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 32, 32, 64)   0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 32, 32, 16)   1024        activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 32, 32, 16)   64          conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 32, 32, 16)   0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 32, 32, 16)   2304        activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 32, 32, 16)   64          conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 32, 32, 16)   0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 32, 32, 64)   1024        activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 32, 32, 64)   0           conv2d_28[0][0]                  \n",
      "                                                                 add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 32, 32, 64)   256         add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 32, 32, 64)   0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 32, 32, 32)   2048        activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 32, 32, 32)   128         conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 32, 32, 32)   0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 16, 16, 32)   9216        activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 16, 16, 32)   128         conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 16, 16, 32)   0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 16, 16, 128)  4096        activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 16, 16, 128)  8192        activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 16, 16, 128)  0           conv2d_31[0][0]                  \n",
      "                                                                 conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 16, 16, 128)  512         add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 16, 16, 128)  0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 16, 16, 32)   4096        activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 16, 16, 32)   128         conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 16, 16, 32)   0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 16, 16, 32)   9216        activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 16, 16, 32)   128         conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 16, 16, 32)   0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 16, 16, 128)  4096        activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 16, 16, 128)  0           conv2d_35[0][0]                  \n",
      "                                                                 add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 16, 16, 128)  512         add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 16, 16, 128)  0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 16, 16, 32)   4096        activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 16, 16, 32)   128         conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 16, 16, 32)   0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 16, 16, 32)   9216        activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 16, 16, 32)   128         conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 16, 16, 32)   0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 16, 16, 128)  4096        activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 16, 16, 128)  0           conv2d_38[0][0]                  \n",
      "                                                                 add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 16, 16, 128)  512         add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 16, 16, 128)  0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 16, 16, 32)   4096        activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 16, 16, 32)   128         conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 16, 16, 32)   0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 16, 16, 32)   9216        activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 16, 16, 32)   128         conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 16, 16, 32)   0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 16, 16, 128)  4096        activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 16, 16, 128)  0           conv2d_41[0][0]                  \n",
      "                                                                 add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 16, 16, 128)  512         add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 16, 16, 128)  0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 16, 16, 32)   4096        activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 16, 16, 32)   128         conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 16, 16, 32)   0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 16, 16, 32)   9216        activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 16, 16, 32)   128         conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 16, 16, 32)   0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 16, 16, 128)  4096        activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 16, 16, 128)  0           conv2d_44[0][0]                  \n",
      "                                                                 add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 16, 16, 128)  512         add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 16, 16, 128)  0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 16, 16, 32)   4096        activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 16, 16, 32)   128         conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 16, 16, 32)   0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 16, 16, 32)   9216        activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 16, 16, 32)   128         conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 16, 16, 32)   0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 16, 16, 128)  4096        activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 16, 16, 128)  0           conv2d_47[0][0]                  \n",
      "                                                                 add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 16, 16, 128)  512         add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 16, 16, 128)  0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 16, 16, 32)   4096        activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 16, 16, 32)   128         conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 16, 16, 32)   0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 16, 16, 32)   9216        activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 16, 16, 32)   128         conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 16, 16, 32)   0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 16, 16, 128)  4096        activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 16, 16, 128)  0           conv2d_50[0][0]                  \n",
      "                                                                 add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 16, 16, 128)  512         add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 16, 16, 128)  0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 16, 16, 32)   4096        activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 16, 16, 32)   128         conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 16, 16, 32)   0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 16, 16, 32)   9216        activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 16, 16, 32)   128         conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 16, 16, 32)   0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 16, 16, 128)  4096        activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 16, 16, 128)  0           conv2d_53[0][0]                  \n",
      "                                                                 add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 16, 16, 128)  512         add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 16, 16, 128)  0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 16, 16, 32)   4096        activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 16, 16, 32)   128         conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 16, 16, 32)   0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 16, 16, 32)   9216        activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 16, 16, 32)   128         conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 16, 16, 32)   0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 16, 16, 128)  4096        activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_17 (Add)                    (None, 16, 16, 128)  0           conv2d_56[0][0]                  \n",
      "                                                                 add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 16, 16, 128)  512         add_17[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 16, 16, 128)  0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 16, 16, 64)   8192        activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 16, 16, 64)   256         conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 16, 16, 64)   0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 8, 8, 64)     36864       activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 8, 8, 64)     256         conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 8, 8, 64)     0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 8, 8, 256)    16384       activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 8, 8, 256)    32768       activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_18 (Add)                    (None, 8, 8, 256)    0           conv2d_59[0][0]                  \n",
      "                                                                 conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 8, 8, 256)    1024        add_18[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 8, 8, 256)    0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 8, 8, 64)     16384       activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 8, 8, 64)     256         conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 8, 8, 64)     0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 8, 8, 64)     36864       activation_58[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 8, 8, 64)     256         conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 8, 8, 64)     0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 8, 8, 256)    16384       activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_19 (Add)                    (None, 8, 8, 256)    0           conv2d_63[0][0]                  \n",
      "                                                                 add_18[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 8, 8, 256)    1024        add_19[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 8, 8, 256)    0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 8, 8, 64)     16384       activation_60[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 8, 8, 64)     256         conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 8, 8, 64)     0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 8, 8, 64)     36864       activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 8, 8, 64)     256         conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 8, 8, 64)     0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 8, 8, 256)    16384       activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_20 (Add)                    (None, 8, 8, 256)    0           conv2d_66[0][0]                  \n",
      "                                                                 add_19[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 8, 8, 256)    1024        add_20[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 8, 8, 256)    0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 8, 8, 64)     16384       activation_63[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 8, 8, 64)     256         conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 8, 8, 64)     0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 8, 8, 64)     36864       activation_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 8, 8, 64)     256         conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 8, 8, 64)     0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 8, 8, 256)    16384       activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_21 (Add)                    (None, 8, 8, 256)    0           conv2d_69[0][0]                  \n",
      "                                                                 add_20[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 8, 8, 256)    1024        add_21[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 8, 8, 256)    0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 8, 8, 64)     16384       activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 8, 8, 64)     256         conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 8, 8, 64)     0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 8, 8, 64)     36864       activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 8, 8, 64)     256         conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 8, 8, 64)     0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 8, 8, 256)    16384       activation_68[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_22 (Add)                    (None, 8, 8, 256)    0           conv2d_72[0][0]                  \n",
      "                                                                 add_21[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, 8, 8, 256)    1024        add_22[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, 8, 8, 256)    0           batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 8, 8, 64)     16384       activation_69[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, 8, 8, 64)     256         conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, 8, 8, 64)     0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 8, 8, 64)     36864       activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, 8, 8, 64)     256         conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, 8, 8, 64)     0           batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 8, 8, 256)    16384       activation_71[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_23 (Add)                    (None, 8, 8, 256)    0           conv2d_75[0][0]                  \n",
      "                                                                 add_22[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, 8, 8, 256)    1024        add_23[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, 8, 8, 256)    0           batch_normalization_73[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 8, 8, 64)     16384       activation_72[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, 8, 8, 64)     256         conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, 8, 8, 64)     0           batch_normalization_74[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, 8, 8, 64)     36864       activation_73[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (None, 8, 8, 64)     256         conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (None, 8, 8, 64)     0           batch_normalization_75[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, 8, 8, 256)    16384       activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_24 (Add)                    (None, 8, 8, 256)    0           conv2d_78[0][0]                  \n",
      "                                                                 add_23[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, 8, 8, 256)    1024        add_24[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (None, 8, 8, 256)    0           batch_normalization_76[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 8, 8, 64)     16384       activation_75[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, 8, 8, 64)     256         conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, 8, 8, 64)     0           batch_normalization_77[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 8, 8, 64)     36864       activation_76[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, 8, 8, 64)     256         conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, 8, 8, 64)     0           batch_normalization_78[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 8, 8, 256)    16384       activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_25 (Add)                    (None, 8, 8, 256)    0           conv2d_81[0][0]                  \n",
      "                                                                 add_24[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, 8, 8, 256)    1024        add_25[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, 8, 8, 256)    0           batch_normalization_79[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, 8, 8, 64)     16384       activation_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, 8, 8, 64)     256         conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, 8, 8, 64)     0           batch_normalization_80[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, 8, 8, 64)     36864       activation_79[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNo (None, 8, 8, 64)     256         conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_80 (Activation)      (None, 8, 8, 64)     0           batch_normalization_81[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, 8, 8, 256)    16384       activation_80[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_26 (Add)                    (None, 8, 8, 256)    0           conv2d_84[0][0]                  \n",
      "                                                                 add_25[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNo (None, 8, 8, 256)    1024        add_26[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_81 (Activation)      (None, 8, 8, 256)    0           batch_normalization_82[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d (AveragePooli (None, 1, 1, 256)    0           activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 256)          0           average_pooling2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 10)           2570        flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_82 (Activation)      (None, 10)           0           dense[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 886,102\n",
      "Trainable params: 873,872\n",
      "Non-trainable params: 12,230\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "[INFO] training network...\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 390 steps, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "390/390 [==============================] - 66s 170ms/step - loss: 2.2020 - accuracy: 0.3508 - val_loss: 1.9591 - val_accuracy: 0.4441\n",
      "Epoch 2/100\n",
      "390/390 [==============================] - 50s 127ms/step - loss: 1.8352 - accuracy: 0.4977 - val_loss: 1.7388 - val_accuracy: 0.5357\n",
      "Epoch 3/100\n",
      "390/390 [==============================] - 50s 128ms/step - loss: 1.6421 - accuracy: 0.5742 - val_loss: 1.5907 - val_accuracy: 0.5960\n",
      "Epoch 4/100\n",
      "390/390 [==============================] - 50s 128ms/step - loss: 1.4979 - accuracy: 0.6277 - val_loss: 1.4261 - val_accuracy: 0.6493\n",
      "Epoch 5/100\n",
      "390/390 [==============================] - 50s 129ms/step - loss: 1.3887 - accuracy: 0.6665 - val_loss: 1.5691 - val_accuracy: 0.6018\n",
      "Epoch 6/100\n",
      "390/390 [==============================] - 50s 129ms/step - loss: 1.2975 - accuracy: 0.7000 - val_loss: 1.3301 - val_accuracy: 0.6923\n",
      "Epoch 7/100\n",
      "390/390 [==============================] - 50s 129ms/step - loss: 1.2160 - accuracy: 0.7298 - val_loss: 1.3784 - val_accuracy: 0.6907\n",
      "Epoch 8/100\n",
      "390/390 [==============================] - 50s 129ms/step - loss: 1.1505 - accuracy: 0.7511 - val_loss: 1.2321 - val_accuracy: 0.7283\n",
      "Epoch 9/100\n",
      "390/390 [==============================] - 50s 129ms/step - loss: 1.0914 - accuracy: 0.7721 - val_loss: 1.1337 - val_accuracy: 0.7633\n",
      "Epoch 10/100\n",
      "390/390 [==============================] - 50s 129ms/step - loss: 1.0453 - accuracy: 0.7871 - val_loss: 1.1451 - val_accuracy: 0.7492\n",
      "Epoch 11/100\n",
      "390/390 [==============================] - 50s 129ms/step - loss: 1.0070 - accuracy: 0.7983 - val_loss: 1.1393 - val_accuracy: 0.7623\n",
      "Epoch 12/100\n",
      "390/390 [==============================] - 50s 129ms/step - loss: 0.9728 - accuracy: 0.8091 - val_loss: 1.1188 - val_accuracy: 0.7688\n",
      "Epoch 13/100\n",
      "390/390 [==============================] - 50s 129ms/step - loss: 0.9371 - accuracy: 0.8206 - val_loss: 1.0472 - val_accuracy: 0.7845\n",
      "Epoch 14/100\n",
      "390/390 [==============================] - 50s 129ms/step - loss: 0.9111 - accuracy: 0.8294 - val_loss: 1.0664 - val_accuracy: 0.7792\n",
      "Epoch 15/100\n",
      "390/390 [==============================] - 50s 129ms/step - loss: 0.8867 - accuracy: 0.8353 - val_loss: 0.9814 - val_accuracy: 0.8071\n",
      "Epoch 16/100\n",
      "390/390 [==============================] - 50s 129ms/step - loss: 0.8577 - accuracy: 0.8440 - val_loss: 1.0228 - val_accuracy: 0.8036\n",
      "Epoch 17/100\n",
      "390/390 [==============================] - 50s 129ms/step - loss: 0.8370 - accuracy: 0.8500 - val_loss: 0.9626 - val_accuracy: 0.8163\n",
      "Epoch 18/100\n",
      "390/390 [==============================] - 55s 141ms/step - loss: 0.8159 - accuracy: 0.8566 - val_loss: 0.9573 - val_accuracy: 0.8193\n",
      "Epoch 19/100\n",
      "390/390 [==============================] - 59s 150ms/step - loss: 0.7982 - accuracy: 0.8610 - val_loss: 1.0373 - val_accuracy: 0.7892\n",
      "Epoch 20/100\n",
      "390/390 [==============================] - 58s 148ms/step - loss: 0.7765 - accuracy: 0.8672 - val_loss: 1.0442 - val_accuracy: 0.7863\n",
      "Epoch 21/100\n",
      "390/390 [==============================] - 57s 145ms/step - loss: 0.7622 - accuracy: 0.8716 - val_loss: 0.9045 - val_accuracy: 0.8259\n",
      "Epoch 22/100\n",
      "390/390 [==============================] - 57s 146ms/step - loss: 0.7435 - accuracy: 0.8764 - val_loss: 0.9160 - val_accuracy: 0.8241\n",
      "Epoch 23/100\n",
      "390/390 [==============================] - 58s 149ms/step - loss: 0.7321 - accuracy: 0.8788 - val_loss: 0.9208 - val_accuracy: 0.8229\n",
      "Epoch 24/100\n",
      "390/390 [==============================] - 59s 150ms/step - loss: 0.7150 - accuracy: 0.8847 - val_loss: 0.9150 - val_accuracy: 0.8285\n",
      "Epoch 25/100\n",
      "390/390 [==============================] - 59s 150ms/step - loss: 0.6969 - accuracy: 0.8900 - val_loss: 0.9551 - val_accuracy: 0.8163\n",
      "Epoch 26/100\n",
      "390/390 [==============================] - 57s 147ms/step - loss: 0.6897 - accuracy: 0.8909 - val_loss: 0.9179 - val_accuracy: 0.8243\n",
      "Epoch 27/100\n",
      "390/390 [==============================] - 57s 145ms/step - loss: 0.6737 - accuracy: 0.8953 - val_loss: 0.8441 - val_accuracy: 0.8403\n",
      "Epoch 28/100\n",
      "390/390 [==============================] - 58s 149ms/step - loss: 0.6632 - accuracy: 0.8971 - val_loss: 0.8662 - val_accuracy: 0.8371\n",
      "Epoch 29/100\n",
      "390/390 [==============================] - 58s 150ms/step - loss: 0.6496 - accuracy: 0.8999 - val_loss: 0.8836 - val_accuracy: 0.8336\n",
      "Epoch 30/100\n",
      "390/390 [==============================] - 58s 149ms/step - loss: 0.6376 - accuracy: 0.9036 - val_loss: 0.8810 - val_accuracy: 0.8302\n",
      "Epoch 31/100\n",
      "390/390 [==============================] - 57s 145ms/step - loss: 0.6287 - accuracy: 0.9064 - val_loss: 0.8130 - val_accuracy: 0.8484\n",
      "Epoch 32/100\n",
      "390/390 [==============================] - 57s 146ms/step - loss: 0.6170 - accuracy: 0.9079 - val_loss: 0.8407 - val_accuracy: 0.8425\n",
      "Epoch 33/100\n",
      "390/390 [==============================] - 51s 131ms/step - loss: 0.6131 - accuracy: 0.9093 - val_loss: 0.8446 - val_accuracy: 0.8481\n",
      "Epoch 34/100\n",
      "390/390 [==============================] - 51s 132ms/step - loss: 0.6021 - accuracy: 0.9108 - val_loss: 0.8275 - val_accuracy: 0.8484\n",
      "Epoch 35/100\n",
      "390/390 [==============================] - 51s 132ms/step - loss: 0.5902 - accuracy: 0.9157 - val_loss: 0.8645 - val_accuracy: 0.8397\n",
      "Epoch 36/100\n",
      "390/390 [==============================] - 51s 132ms/step - loss: 0.5788 - accuracy: 0.9182 - val_loss: 0.8556 - val_accuracy: 0.8410\n",
      "Epoch 37/100\n",
      "390/390 [==============================] - 51s 131ms/step - loss: 0.5722 - accuracy: 0.9186 - val_loss: 0.8009 - val_accuracy: 0.8511\n",
      "Epoch 38/100\n",
      "390/390 [==============================] - 51s 132ms/step - loss: 0.5630 - accuracy: 0.9218 - val_loss: 0.7708 - val_accuracy: 0.8651\n",
      "Epoch 39/100\n",
      "390/390 [==============================] - 51s 132ms/step - loss: 0.5565 - accuracy: 0.9226 - val_loss: 0.8111 - val_accuracy: 0.8538\n",
      "Epoch 40/100\n",
      "390/390 [==============================] - 53s 136ms/step - loss: 0.5468 - accuracy: 0.9245 - val_loss: 0.8129 - val_accuracy: 0.8507\n",
      "Epoch 41/100\n",
      "390/390 [==============================] - 53s 137ms/step - loss: 0.5390 - accuracy: 0.9268 - val_loss: 0.7350 - val_accuracy: 0.8729\n",
      "Epoch 42/100\n",
      "390/390 [==============================] - 51s 132ms/step - loss: 0.5314 - accuracy: 0.9284 - val_loss: 0.8319 - val_accuracy: 0.8497\n",
      "Epoch 43/100\n",
      "390/390 [==============================] - 56s 144ms/step - loss: 0.5255 - accuracy: 0.9297 - val_loss: 0.8621 - val_accuracy: 0.8363\n",
      "Epoch 44/100\n",
      "390/390 [==============================] - 54s 137ms/step - loss: 0.5227 - accuracy: 0.9305 - val_loss: 0.8468 - val_accuracy: 0.8389\n",
      "Epoch 45/100\n",
      "390/390 [==============================] - 50s 129ms/step - loss: 0.5095 - accuracy: 0.9341 - val_loss: 0.8236 - val_accuracy: 0.8487\n",
      "Epoch 46/100\n",
      "390/390 [==============================] - 50s 129ms/step - loss: 0.5082 - accuracy: 0.9317 - val_loss: 0.8895 - val_accuracy: 0.8377\n",
      "Epoch 47/100\n",
      "390/390 [==============================] - 51s 129ms/step - loss: 0.4982 - accuracy: 0.9368 - val_loss: 0.8532 - val_accuracy: 0.8467\n",
      "Epoch 48/100\n",
      "390/390 [==============================] - 50s 129ms/step - loss: 0.4921 - accuracy: 0.9375 - val_loss: 0.8181 - val_accuracy: 0.8479\n",
      "Epoch 49/100\n",
      "390/390 [==============================] - 51s 130ms/step - loss: 0.4912 - accuracy: 0.9373 - val_loss: 0.8300 - val_accuracy: 0.8403\n",
      "Epoch 50/100\n",
      "390/390 [==============================] - 51s 130ms/step - loss: 0.4808 - accuracy: 0.9396 - val_loss: 0.8250 - val_accuracy: 0.8523\n",
      "Epoch 51/100\n",
      "390/390 [==============================] - 50s 129ms/step - loss: 0.4760 - accuracy: 0.9402 - val_loss: 0.8031 - val_accuracy: 0.8504\n",
      "Epoch 52/100\n",
      "390/390 [==============================] - 50s 129ms/step - loss: 0.4706 - accuracy: 0.9406 - val_loss: 0.7072 - val_accuracy: 0.8749\n",
      "Epoch 53/100\n",
      "390/390 [==============================] - 51s 130ms/step - loss: 0.4627 - accuracy: 0.9432 - val_loss: 0.8232 - val_accuracy: 0.8442\n",
      "Epoch 54/100\n",
      "390/390 [==============================] - 51s 130ms/step - loss: 0.4624 - accuracy: 0.9432 - val_loss: 0.7771 - val_accuracy: 0.8504\n",
      "Epoch 55/100\n",
      "390/390 [==============================] - 51s 130ms/step - loss: 0.4576 - accuracy: 0.9440 - val_loss: 0.8297 - val_accuracy: 0.8425\n",
      "Epoch 56/100\n",
      "390/390 [==============================] - 51s 130ms/step - loss: 0.4488 - accuracy: 0.9466 - val_loss: 0.7018 - val_accuracy: 0.8760\n",
      "Epoch 57/100\n",
      "390/390 [==============================] - 51s 130ms/step - loss: 0.4455 - accuracy: 0.9465 - val_loss: 0.8402 - val_accuracy: 0.8471\n",
      "Epoch 58/100\n",
      "390/390 [==============================] - 55s 142ms/step - loss: 0.4436 - accuracy: 0.9470 - val_loss: 0.7328 - val_accuracy: 0.8643\n",
      "Epoch 59/100\n",
      "390/390 [==============================] - 56s 144ms/step - loss: 0.4358 - accuracy: 0.9481 - val_loss: 0.9438 - val_accuracy: 0.8291\n",
      "Epoch 60/100\n",
      "390/390 [==============================] - 58s 149ms/step - loss: 0.4357 - accuracy: 0.9483 - val_loss: 0.7481 - val_accuracy: 0.8671\n",
      "Epoch 61/100\n",
      "390/390 [==============================] - 58s 150ms/step - loss: 0.4248 - accuracy: 0.9514 - val_loss: 0.8547 - val_accuracy: 0.8485\n",
      "Epoch 62/100\n",
      "390/390 [==============================] - 62s 158ms/step - loss: 0.4228 - accuracy: 0.9520 - val_loss: 0.7024 - val_accuracy: 0.8730\n",
      "Epoch 63/100\n",
      "390/390 [==============================] - 57s 146ms/step - loss: 0.4200 - accuracy: 0.9507 - val_loss: 0.7230 - val_accuracy: 0.8679\n",
      "Epoch 64/100\n",
      "390/390 [==============================] - 57s 145ms/step - loss: 0.4160 - accuracy: 0.9525 - val_loss: 0.7514 - val_accuracy: 0.8597\n",
      "Epoch 65/100\n",
      "390/390 [==============================] - 57s 145ms/step - loss: 0.4078 - accuracy: 0.9551 - val_loss: 0.6992 - val_accuracy: 0.8729\n",
      "Epoch 66/100\n",
      "390/390 [==============================] - 57s 146ms/step - loss: 0.4092 - accuracy: 0.9533 - val_loss: 0.7387 - val_accuracy: 0.8668\n",
      "Epoch 67/100\n",
      "390/390 [==============================] - 51s 131ms/step - loss: 0.4030 - accuracy: 0.9547 - val_loss: 0.6860 - val_accuracy: 0.8768\n",
      "Epoch 68/100\n",
      "390/390 [==============================] - 52s 132ms/step - loss: 0.3957 - accuracy: 0.9570 - val_loss: 0.9538 - val_accuracy: 0.8323\n",
      "Epoch 69/100\n",
      "390/390 [==============================] - 51s 132ms/step - loss: 0.3990 - accuracy: 0.9555 - val_loss: 0.7193 - val_accuracy: 0.8700\n",
      "Epoch 70/100\n",
      "390/390 [==============================] - 51s 132ms/step - loss: 0.3976 - accuracy: 0.9553 - val_loss: 0.6824 - val_accuracy: 0.8843\n",
      "Epoch 71/100\n",
      "390/390 [==============================] - 51s 132ms/step - loss: 0.3867 - accuracy: 0.9584 - val_loss: 0.7926 - val_accuracy: 0.8568\n",
      "Epoch 72/100\n",
      "390/390 [==============================] - 51s 132ms/step - loss: 0.3857 - accuracy: 0.9593 - val_loss: 0.6934 - val_accuracy: 0.8762\n",
      "Epoch 73/100\n",
      "390/390 [==============================] - 60s 153ms/step - loss: 0.3805 - accuracy: 0.9590 - val_loss: 0.7330 - val_accuracy: 0.8609\n",
      "Epoch 74/100\n",
      "390/390 [==============================] - 56s 145ms/step - loss: 0.3836 - accuracy: 0.9582 - val_loss: 0.7237 - val_accuracy: 0.8692\n",
      "Epoch 75/100\n",
      "390/390 [==============================] - 57s 147ms/step - loss: 0.3781 - accuracy: 0.9601 - val_loss: 0.7600 - val_accuracy: 0.8684\n",
      "Epoch 76/100\n",
      "390/390 [==============================] - 59s 150ms/step - loss: 0.3721 - accuracy: 0.9616 - val_loss: 0.6762 - val_accuracy: 0.8816\n",
      "Epoch 77/100\n",
      "390/390 [==============================] - 58s 149ms/step - loss: 0.3684 - accuracy: 0.9620 - val_loss: 0.7079 - val_accuracy: 0.8744\n",
      "Epoch 78/100\n",
      "390/390 [==============================] - 58s 150ms/step - loss: 0.3660 - accuracy: 0.9612 - val_loss: 0.7077 - val_accuracy: 0.8737\n",
      "Epoch 79/100\n",
      "390/390 [==============================] - 57s 146ms/step - loss: 0.3670 - accuracy: 0.9611 - val_loss: 0.7145 - val_accuracy: 0.8691\n",
      "Epoch 80/100\n",
      "390/390 [==============================] - 58s 148ms/step - loss: 0.3647 - accuracy: 0.9606 - val_loss: 0.7922 - val_accuracy: 0.8591\n",
      "Epoch 81/100\n",
      "390/390 [==============================] - 57s 146ms/step - loss: 0.3640 - accuracy: 0.9607 - val_loss: 0.6716 - val_accuracy: 0.8825\n",
      "Epoch 82/100\n",
      "390/390 [==============================] - 58s 150ms/step - loss: 0.3565 - accuracy: 0.9632 - val_loss: 0.6968 - val_accuracy: 0.8771\n",
      "Epoch 83/100\n",
      "390/390 [==============================] - 59s 150ms/step - loss: 0.3563 - accuracy: 0.9631 - val_loss: 0.6593 - val_accuracy: 0.8849\n",
      "Epoch 84/100\n",
      "390/390 [==============================] - 58s 149ms/step - loss: 0.3516 - accuracy: 0.9646 - val_loss: 0.7407 - val_accuracy: 0.8721\n",
      "Epoch 85/100\n",
      "390/390 [==============================] - 57s 146ms/step - loss: 0.3514 - accuracy: 0.9638 - val_loss: 0.6628 - val_accuracy: 0.8801\n",
      "Epoch 86/100\n",
      "390/390 [==============================] - 56s 144ms/step - loss: 0.3492 - accuracy: 0.9635 - val_loss: 0.6871 - val_accuracy: 0.8770\n",
      "Epoch 87/100\n",
      "390/390 [==============================] - 51s 132ms/step - loss: 0.3451 - accuracy: 0.9654 - val_loss: 0.6984 - val_accuracy: 0.8777\n",
      "Epoch 88/100\n",
      "390/390 [==============================] - 51s 131ms/step - loss: 0.3387 - accuracy: 0.9669 - val_loss: 0.6761 - val_accuracy: 0.8818\n",
      "Epoch 89/100\n",
      "390/390 [==============================] - 51s 132ms/step - loss: 0.3390 - accuracy: 0.9666 - val_loss: 0.6685 - val_accuracy: 0.8813\n",
      "Epoch 90/100\n",
      "390/390 [==============================] - 51s 132ms/step - loss: 0.3327 - accuracy: 0.9683 - val_loss: 0.6827 - val_accuracy: 0.8798\n",
      "Epoch 91/100\n",
      "390/390 [==============================] - 51s 132ms/step - loss: 0.3389 - accuracy: 0.9653 - val_loss: 0.6641 - val_accuracy: 0.8835\n",
      "Epoch 92/100\n",
      "390/390 [==============================] - 51s 131ms/step - loss: 0.3341 - accuracy: 0.9651 - val_loss: 0.7090 - val_accuracy: 0.8771\n",
      "Epoch 93/100\n",
      "390/390 [==============================] - 51s 132ms/step - loss: 0.3318 - accuracy: 0.9677 - val_loss: 0.7231 - val_accuracy: 0.8665\n",
      "Epoch 94/100\n",
      "390/390 [==============================] - 51s 131ms/step - loss: 0.3253 - accuracy: 0.9692 - val_loss: 0.6648 - val_accuracy: 0.8842\n",
      "Epoch 95/100\n",
      "390/390 [==============================] - 51s 132ms/step - loss: 0.3257 - accuracy: 0.9683 - val_loss: 0.7588 - val_accuracy: 0.8633\n",
      "Epoch 96/100\n",
      "390/390 [==============================] - 51s 132ms/step - loss: 0.3246 - accuracy: 0.9682 - val_loss: 0.7176 - val_accuracy: 0.8723\n",
      "Epoch 97/100\n",
      "390/390 [==============================] - 51s 132ms/step - loss: 0.3222 - accuracy: 0.9684 - val_loss: 0.8851 - val_accuracy: 0.8507\n",
      "Epoch 98/100\n",
      "390/390 [==============================] - 51s 131ms/step - loss: 0.3261 - accuracy: 0.9669 - val_loss: 0.6876 - val_accuracy: 0.8750\n",
      "Epoch 99/100\n",
      "390/390 [==============================] - 51s 132ms/step - loss: 0.3190 - accuracy: 0.9688 - val_loss: 0.6844 - val_accuracy: 0.8770\n",
      "Epoch 100/100\n",
      "390/390 [==============================] - 51s 131ms/step - loss: 0.3116 - accuracy: 0.9716 - val_loss: 0.7609 - val_accuracy: 0.8599\n",
      "\n",
      " Test accuracy\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8935    0.8890    0.8912      1000\n",
      "           1     0.8719    0.9800    0.9228      1000\n",
      "           2     0.8136    0.8510    0.8319      1000\n",
      "           3     0.8545    0.5930    0.7001      1000\n",
      "           4     0.9572    0.7380    0.8334      1000\n",
      "           5     0.6424    0.9450    0.7649      1000\n",
      "           6     0.8985    0.9120    0.9052      1000\n",
      "           7     0.9133    0.9170    0.9152      1000\n",
      "           8     0.9817    0.8560    0.9145      1000\n",
      "           9     0.9107    0.9180    0.9143      1000\n",
      "\n",
      "    accuracy                         0.8599     10000\n",
      "   macro avg     0.8737    0.8599    0.8594     10000\n",
      "weighted avg     0.8737    0.8599    0.8594     10000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x18e8aeaf188>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load the training and testing data\n",
    "print(\"[INFO] loading CIFAR-10 data...\")\n",
    "((trainX, trainY), (testX, testY)) = cifar10.load_data()\n",
    "trainX = trainX.astype(\"float\")\n",
    "testX = testX.astype(\"float\")\n",
    "\n",
    "# apply mean subtraction to the data\n",
    "mean = np.mean(trainX, axis=0)\n",
    "trainX -= mean\n",
    "testX -= mean\n",
    "\n",
    "# convert the labels from integers to vectors\n",
    "lb = LabelBinarizer()\n",
    "trainY = lb.fit_transform(trainY)\n",
    "testY = lb.transform(testY)\n",
    "\n",
    "aug = ImageDataGenerator(width_shift_range = 0.1, height_shift_range = 0.1, horizontal_flip = True, fill_mode=\"nearest\")\n",
    "\n",
    "print(\"[INFO] compiling model...\")\n",
    "opt = SGD(lr = 0.1)\n",
    "model = ResNet.build(32, 32, 3, 10, (9, 9, 9), (64, 64, 128, 256), reg=0.0005)\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = opt, metrics=['accuracy'])\n",
    "\n",
    "# print a model summary\n",
    "print(model.summary())\n",
    "\n",
    "print(\"[INFO] training network...\")\n",
    "H = model.fit(aug.flow(trainX, trainY, batch_size=128), validation_data=(testX, testY),\n",
    "              steps_per_epoch=len(trainX) // 128, epochs=100, verbose=1)\n",
    "\n",
    "# print a classification report\n",
    "print('\\n Test accuracy')\n",
    "predictedY = model.predict(testX)\n",
    "predictedY = predictedY.argmax(axis=1)\n",
    "testY = testY.argmax(axis=1)\n",
    "print(classification_report(testY, predictedY, digits=4))\n",
    "\n",
    "# plot the training loss and accuracy\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(np.arange(0, 100), H.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(np.arange(0, 100), H.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(np.arange(0, 100), H.history[\"accuracy\"], label=\"train_acc\")\n",
    "plt.plot(np.arange(0, 100), H.history[\"val_accuracy\"], label=\"val_acc\")\n",
    "plt.title(\"Training Loss and Accuracy\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResNet Experiment 2: Data Augmentation and a Learning Rate Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading CIFAR-10 data...\n",
      "[INFO] compiling model...\n",
      "[INFO] training network...\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 390 steps, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "390/390 [==============================] - 62s 160ms/step - loss: 2.2054 - accuracy: 0.3525 - val_loss: 1.9545 - val_accuracy: 0.4573\n",
      "Epoch 2/100\n",
      "390/390 [==============================] - 50s 129ms/step - loss: 1.8504 - accuracy: 0.4976 - val_loss: 1.7733 - val_accuracy: 0.5244\n",
      "Epoch 3/100\n",
      "390/390 [==============================] - 50s 129ms/step - loss: 1.6691 - accuracy: 0.5634 - val_loss: 1.6154 - val_accuracy: 0.5886\n",
      "Epoch 4/100\n",
      "390/390 [==============================] - 51s 130ms/step - loss: 1.5205 - accuracy: 0.6220 - val_loss: 1.5732 - val_accuracy: 0.6077\n",
      "Epoch 5/100\n",
      "390/390 [==============================] - 51s 130ms/step - loss: 1.4065 - accuracy: 0.6630 - val_loss: 1.5530 - val_accuracy: 0.6298\n",
      "Epoch 6/100\n",
      "390/390 [==============================] - 51s 130ms/step - loss: 1.3090 - accuracy: 0.6994 - val_loss: 1.3292 - val_accuracy: 0.6934\n",
      "Epoch 7/100\n",
      "390/390 [==============================] - 51s 130ms/step - loss: 1.2300 - accuracy: 0.7245 - val_loss: 1.2503 - val_accuracy: 0.7146\n",
      "Epoch 8/100\n",
      "390/390 [==============================] - 51s 131ms/step - loss: 1.1644 - accuracy: 0.7487 - val_loss: 1.3393 - val_accuracy: 0.7032\n",
      "Epoch 9/100\n",
      "390/390 [==============================] - 51s 131ms/step - loss: 1.1111 - accuracy: 0.7668 - val_loss: 1.1726 - val_accuracy: 0.7428\n",
      "Epoch 10/100\n",
      "390/390 [==============================] - 50s 129ms/step - loss: 1.0605 - accuracy: 0.7825 - val_loss: 1.1705 - val_accuracy: 0.7591\n",
      "Epoch 11/100\n",
      "390/390 [==============================] - 51s 130ms/step - loss: 1.0180 - accuracy: 0.7958 - val_loss: 1.1013 - val_accuracy: 0.7740\n",
      "Epoch 12/100\n",
      "390/390 [==============================] - 50s 129ms/step - loss: 0.9822 - accuracy: 0.8082 - val_loss: 1.0909 - val_accuracy: 0.7803\n",
      "Epoch 13/100\n",
      "390/390 [==============================] - 50s 129ms/step - loss: 0.9488 - accuracy: 0.8193 - val_loss: 1.1166 - val_accuracy: 0.7706\n",
      "Epoch 14/100\n",
      "390/390 [==============================] - 51s 130ms/step - loss: 0.9231 - accuracy: 0.8245 - val_loss: 1.0451 - val_accuracy: 0.7895\n",
      "Epoch 15/100\n",
      "390/390 [==============================] - 51s 130ms/step - loss: 0.8939 - accuracy: 0.8348 - val_loss: 1.0529 - val_accuracy: 0.7901\n",
      "Epoch 16/100\n",
      "390/390 [==============================] - 51s 130ms/step - loss: 0.8710 - accuracy: 0.8417 - val_loss: 0.9808 - val_accuracy: 0.8082\n",
      "Epoch 17/100\n",
      "390/390 [==============================] - 51s 130ms/step - loss: 0.8420 - accuracy: 0.8520 - val_loss: 0.9684 - val_accuracy: 0.8103\n",
      "Epoch 18/100\n",
      "390/390 [==============================] - 51s 130ms/step - loss: 0.8243 - accuracy: 0.8562 - val_loss: 0.9865 - val_accuracy: 0.8078\n",
      "Epoch 19/100\n",
      "390/390 [==============================] - 51s 130ms/step - loss: 0.8045 - accuracy: 0.8615 - val_loss: 0.9588 - val_accuracy: 0.8135\n",
      "Epoch 20/100\n",
      "390/390 [==============================] - 51s 130ms/step - loss: 0.7874 - accuracy: 0.8654 - val_loss: 0.8813 - val_accuracy: 0.8405\n",
      "Epoch 21/100\n",
      "390/390 [==============================] - 51s 130ms/step - loss: 0.7696 - accuracy: 0.8714 - val_loss: 0.9304 - val_accuracy: 0.8244\n",
      "Epoch 22/100\n",
      "390/390 [==============================] - 51s 130ms/step - loss: 0.7544 - accuracy: 0.8753 - val_loss: 0.9687 - val_accuracy: 0.8110\n",
      "Epoch 23/100\n",
      "390/390 [==============================] - 51s 132ms/step - loss: 0.7382 - accuracy: 0.8793 - val_loss: 0.9178 - val_accuracy: 0.8293\n",
      "Epoch 24/100\n",
      "390/390 [==============================] - 51s 131ms/step - loss: 0.7197 - accuracy: 0.8845 - val_loss: 0.9579 - val_accuracy: 0.8190\n",
      "Epoch 25/100\n",
      "390/390 [==============================] - 51s 132ms/step - loss: 0.7089 - accuracy: 0.8876 - val_loss: 0.9300 - val_accuracy: 0.8227\n",
      "Epoch 26/100\n",
      "390/390 [==============================] - 51s 131ms/step - loss: 0.6913 - accuracy: 0.8916 - val_loss: 0.8344 - val_accuracy: 0.8518\n",
      "Epoch 27/100\n",
      "390/390 [==============================] - 51s 132ms/step - loss: 0.6826 - accuracy: 0.8942 - val_loss: 0.9389 - val_accuracy: 0.8222\n",
      "Epoch 28/100\n",
      "390/390 [==============================] - 51s 132ms/step - loss: 0.6675 - accuracy: 0.9001 - val_loss: 0.8459 - val_accuracy: 0.8478\n",
      "Epoch 29/100\n",
      "390/390 [==============================] - 51s 132ms/step - loss: 0.6569 - accuracy: 0.9019 - val_loss: 0.9248 - val_accuracy: 0.8261\n",
      "Epoch 30/100\n",
      "390/390 [==============================] - 51s 131ms/step - loss: 0.6510 - accuracy: 0.9034 - val_loss: 0.8753 - val_accuracy: 0.8374\n",
      "Epoch 31/100\n",
      "390/390 [==============================] - 51s 132ms/step - loss: 0.6351 - accuracy: 0.9071 - val_loss: 0.8083 - val_accuracy: 0.8599\n",
      "Epoch 32/100\n",
      "390/390 [==============================] - 51s 132ms/step - loss: 0.6243 - accuracy: 0.9123 - val_loss: 0.8450 - val_accuracy: 0.8483\n",
      "Epoch 33/100\n",
      "390/390 [==============================] - 51s 131ms/step - loss: 0.6107 - accuracy: 0.9143 - val_loss: 0.8996 - val_accuracy: 0.8406\n",
      "Epoch 34/100\n",
      "390/390 [==============================] - 51s 132ms/step - loss: 0.6034 - accuracy: 0.9166 - val_loss: 0.8431 - val_accuracy: 0.8463\n",
      "Epoch 35/100\n",
      "390/390 [==============================] - 51s 131ms/step - loss: 0.5962 - accuracy: 0.9188 - val_loss: 0.8700 - val_accuracy: 0.8416\n",
      "Epoch 36/100\n",
      "390/390 [==============================] - 51s 132ms/step - loss: 0.5828 - accuracy: 0.9209 - val_loss: 0.8451 - val_accuracy: 0.8449\n",
      "Epoch 37/100\n",
      "390/390 [==============================] - 51s 131ms/step - loss: 0.5719 - accuracy: 0.9237 - val_loss: 0.8213 - val_accuracy: 0.8539\n",
      "Epoch 38/100\n",
      "390/390 [==============================] - 51s 131ms/step - loss: 0.5647 - accuracy: 0.9255 - val_loss: 0.8184 - val_accuracy: 0.8567\n",
      "Epoch 39/100\n",
      "390/390 [==============================] - 51s 131ms/step - loss: 0.5567 - accuracy: 0.9284 - val_loss: 0.7959 - val_accuracy: 0.8597\n",
      "Epoch 40/100\n",
      "390/390 [==============================] - 51s 131ms/step - loss: 0.5464 - accuracy: 0.9312 - val_loss: 0.9140 - val_accuracy: 0.8378\n",
      "Epoch 41/100\n",
      "390/390 [==============================] - 51s 132ms/step - loss: 0.5439 - accuracy: 0.9316 - val_loss: 0.8098 - val_accuracy: 0.8584\n",
      "Epoch 42/100\n",
      "390/390 [==============================] - 51s 132ms/step - loss: 0.5312 - accuracy: 0.9368 - val_loss: 0.8409 - val_accuracy: 0.8501\n",
      "Epoch 43/100\n",
      "390/390 [==============================] - 51s 132ms/step - loss: 0.5224 - accuracy: 0.9375 - val_loss: 0.8356 - val_accuracy: 0.8510\n",
      "Epoch 44/100\n",
      "390/390 [==============================] - 51s 132ms/step - loss: 0.5175 - accuracy: 0.9381 - val_loss: 0.8179 - val_accuracy: 0.8562\n",
      "Epoch 45/100\n",
      "390/390 [==============================] - 51s 132ms/step - loss: 0.5114 - accuracy: 0.9387 - val_loss: 0.7871 - val_accuracy: 0.8680\n",
      "Epoch 46/100\n",
      "390/390 [==============================] - 51s 132ms/step - loss: 0.5038 - accuracy: 0.9427 - val_loss: 0.8145 - val_accuracy: 0.8561\n",
      "Epoch 47/100\n",
      "390/390 [==============================] - 51s 132ms/step - loss: 0.4950 - accuracy: 0.9448 - val_loss: 0.8315 - val_accuracy: 0.8575\n",
      "Epoch 48/100\n",
      "390/390 [==============================] - 51s 132ms/step - loss: 0.4885 - accuracy: 0.9463 - val_loss: 0.9148 - val_accuracy: 0.8420\n",
      "Epoch 49/100\n",
      "390/390 [==============================] - 51s 132ms/step - loss: 0.4785 - accuracy: 0.9485 - val_loss: 0.7588 - val_accuracy: 0.8722\n",
      "Epoch 50/100\n",
      "390/390 [==============================] - 51s 131ms/step - loss: 0.4747 - accuracy: 0.9494 - val_loss: 0.7695 - val_accuracy: 0.8662\n",
      "Epoch 51/100\n",
      "390/390 [==============================] - 51s 131ms/step - loss: 0.4668 - accuracy: 0.9516 - val_loss: 0.7630 - val_accuracy: 0.8717\n",
      "Epoch 52/100\n",
      "390/390 [==============================] - 51s 131ms/step - loss: 0.4612 - accuracy: 0.9530 - val_loss: 0.7753 - val_accuracy: 0.8679\n",
      "Epoch 53/100\n",
      "390/390 [==============================] - 51s 131ms/step - loss: 0.4569 - accuracy: 0.9534 - val_loss: 0.7340 - val_accuracy: 0.8817\n",
      "Epoch 54/100\n",
      "390/390 [==============================] - 51s 131ms/step - loss: 0.4521 - accuracy: 0.9559 - val_loss: 0.8126 - val_accuracy: 0.8597\n",
      "Epoch 55/100\n",
      "390/390 [==============================] - 51s 131ms/step - loss: 0.4473 - accuracy: 0.9559 - val_loss: 0.7997 - val_accuracy: 0.8638\n",
      "Epoch 56/100\n",
      "390/390 [==============================] - 51s 131ms/step - loss: 0.4420 - accuracy: 0.9576 - val_loss: 0.7395 - val_accuracy: 0.8723\n",
      "Epoch 57/100\n",
      "390/390 [==============================] - 51s 131ms/step - loss: 0.4335 - accuracy: 0.9592 - val_loss: 0.7438 - val_accuracy: 0.8766\n",
      "Epoch 58/100\n",
      "390/390 [==============================] - 51s 131ms/step - loss: 0.4260 - accuracy: 0.9621 - val_loss: 0.7758 - val_accuracy: 0.8701\n",
      "Epoch 59/100\n",
      "390/390 [==============================] - 51s 131ms/step - loss: 0.4182 - accuracy: 0.9656 - val_loss: 0.7311 - val_accuracy: 0.8822\n",
      "Epoch 60/100\n",
      "390/390 [==============================] - 51s 131ms/step - loss: 0.4159 - accuracy: 0.9663 - val_loss: 0.7449 - val_accuracy: 0.8775\n",
      "Epoch 61/100\n",
      "390/390 [==============================] - 51s 131ms/step - loss: 0.4106 - accuracy: 0.9667 - val_loss: 0.7834 - val_accuracy: 0.8724\n",
      "Epoch 62/100\n",
      "390/390 [==============================] - 51s 131ms/step - loss: 0.4043 - accuracy: 0.9684 - val_loss: 0.7933 - val_accuracy: 0.8681\n",
      "Epoch 63/100\n",
      "390/390 [==============================] - 51s 130ms/step - loss: 0.4008 - accuracy: 0.9691 - val_loss: 0.8656 - val_accuracy: 0.8560\n",
      "Epoch 64/100\n",
      "390/390 [==============================] - 51s 131ms/step - loss: 0.3940 - accuracy: 0.9710 - val_loss: 0.7404 - val_accuracy: 0.8824\n",
      "Epoch 65/100\n",
      "390/390 [==============================] - 51s 131ms/step - loss: 0.3884 - accuracy: 0.9727 - val_loss: 0.7574 - val_accuracy: 0.8754\n",
      "Epoch 66/100\n",
      "390/390 [==============================] - 51s 131ms/step - loss: 0.3852 - accuracy: 0.9734 - val_loss: 0.7897 - val_accuracy: 0.8766\n",
      "Epoch 67/100\n",
      "390/390 [==============================] - 51s 131ms/step - loss: 0.3855 - accuracy: 0.9721 - val_loss: 0.7704 - val_accuracy: 0.8731\n",
      "Epoch 68/100\n",
      "390/390 [==============================] - 51s 131ms/step - loss: 0.3783 - accuracy: 0.9747 - val_loss: 0.8077 - val_accuracy: 0.8670\n",
      "Epoch 69/100\n",
      "390/390 [==============================] - 51s 131ms/step - loss: 0.3713 - accuracy: 0.9774 - val_loss: 0.7547 - val_accuracy: 0.8800\n",
      "Epoch 70/100\n",
      "390/390 [==============================] - 51s 131ms/step - loss: 0.3676 - accuracy: 0.9780 - val_loss: 0.7383 - val_accuracy: 0.8856\n",
      "Epoch 71/100\n",
      "390/390 [==============================] - 51s 131ms/step - loss: 0.3643 - accuracy: 0.9790 - val_loss: 0.7563 - val_accuracy: 0.8803\n",
      "Epoch 72/100\n",
      "390/390 [==============================] - 51s 131ms/step - loss: 0.3602 - accuracy: 0.9800 - val_loss: 0.7361 - val_accuracy: 0.8850\n",
      "Epoch 73/100\n",
      "390/390 [==============================] - 51s 131ms/step - loss: 0.3551 - accuracy: 0.9817 - val_loss: 0.7446 - val_accuracy: 0.8863\n",
      "Epoch 74/100\n",
      "390/390 [==============================] - 51s 131ms/step - loss: 0.3500 - accuracy: 0.9828 - val_loss: 0.7825 - val_accuracy: 0.8823\n",
      "Epoch 75/100\n",
      "390/390 [==============================] - 51s 131ms/step - loss: 0.3491 - accuracy: 0.9835 - val_loss: 0.7423 - val_accuracy: 0.8851\n",
      "Epoch 76/100\n",
      "390/390 [==============================] - 51s 131ms/step - loss: 0.3450 - accuracy: 0.9842 - val_loss: 0.7519 - val_accuracy: 0.8831\n",
      "Epoch 77/100\n",
      "390/390 [==============================] - 51s 131ms/step - loss: 0.3413 - accuracy: 0.9850 - val_loss: 0.7738 - val_accuracy: 0.8833\n",
      "Epoch 78/100\n",
      "390/390 [==============================] - 51s 131ms/step - loss: 0.3370 - accuracy: 0.9871 - val_loss: 0.7642 - val_accuracy: 0.8818\n",
      "Epoch 79/100\n",
      "390/390 [==============================] - 51s 131ms/step - loss: 0.3335 - accuracy: 0.9864 - val_loss: 0.7393 - val_accuracy: 0.8874\n",
      "Epoch 80/100\n",
      "390/390 [==============================] - 51s 131ms/step - loss: 0.3311 - accuracy: 0.9878 - val_loss: 0.7661 - val_accuracy: 0.8835\n",
      "Epoch 81/100\n",
      "390/390 [==============================] - 51s 131ms/step - loss: 0.3293 - accuracy: 0.9879 - val_loss: 0.7354 - val_accuracy: 0.8866\n",
      "Epoch 82/100\n",
      "390/390 [==============================] - 51s 131ms/step - loss: 0.3263 - accuracy: 0.9884 - val_loss: 0.7564 - val_accuracy: 0.8863\n",
      "Epoch 83/100\n",
      "390/390 [==============================] - 51s 131ms/step - loss: 0.3228 - accuracy: 0.9900 - val_loss: 0.7547 - val_accuracy: 0.8892\n",
      "Epoch 84/100\n",
      "390/390 [==============================] - 51s 131ms/step - loss: 0.3213 - accuracy: 0.9901 - val_loss: 0.7466 - val_accuracy: 0.8887\n",
      "Epoch 85/100\n",
      "390/390 [==============================] - 51s 131ms/step - loss: 0.3198 - accuracy: 0.9903 - val_loss: 0.7446 - val_accuracy: 0.8883\n",
      "Epoch 86/100\n",
      "390/390 [==============================] - 51s 131ms/step - loss: 0.3157 - accuracy: 0.9917 - val_loss: 0.7711 - val_accuracy: 0.8870\n",
      "Epoch 87/100\n",
      "390/390 [==============================] - 51s 131ms/step - loss: 0.3131 - accuracy: 0.9926 - val_loss: 0.7289 - val_accuracy: 0.8935\n",
      "Epoch 88/100\n",
      "390/390 [==============================] - 51s 131ms/step - loss: 0.3109 - accuracy: 0.9931 - val_loss: 0.7413 - val_accuracy: 0.8927\n",
      "Epoch 89/100\n",
      "390/390 [==============================] - 51s 131ms/step - loss: 0.3092 - accuracy: 0.9938 - val_loss: 0.7304 - val_accuracy: 0.8921\n",
      "Epoch 90/100\n",
      "390/390 [==============================] - 51s 131ms/step - loss: 0.3077 - accuracy: 0.9936 - val_loss: 0.7381 - val_accuracy: 0.8934\n",
      "Epoch 91/100\n",
      "390/390 [==============================] - 51s 131ms/step - loss: 0.3058 - accuracy: 0.9945 - val_loss: 0.7365 - val_accuracy: 0.8923\n",
      "Epoch 92/100\n",
      "390/390 [==============================] - 51s 131ms/step - loss: 0.3047 - accuracy: 0.9943 - val_loss: 0.7345 - val_accuracy: 0.8928\n",
      "Epoch 93/100\n",
      "390/390 [==============================] - 51s 130ms/step - loss: 0.3018 - accuracy: 0.9956 - val_loss: 0.7350 - val_accuracy: 0.8935\n",
      "Epoch 94/100\n",
      "390/390 [==============================] - 50s 129ms/step - loss: 0.3023 - accuracy: 0.9948 - val_loss: 0.7389 - val_accuracy: 0.8922\n",
      "Epoch 95/100\n",
      "390/390 [==============================] - 51s 130ms/step - loss: 0.3014 - accuracy: 0.9954 - val_loss: 0.7326 - val_accuracy: 0.8935\n",
      "Epoch 96/100\n",
      "390/390 [==============================] - 51s 130ms/step - loss: 0.3007 - accuracy: 0.9955 - val_loss: 0.7320 - val_accuracy: 0.8940\n",
      "Epoch 97/100\n",
      "390/390 [==============================] - 51s 131ms/step - loss: 0.2983 - accuracy: 0.9963 - val_loss: 0.7323 - val_accuracy: 0.8942\n",
      "Epoch 98/100\n",
      "390/390 [==============================] - 329s 844ms/step - loss: 0.2987 - accuracy: 0.9963 - val_loss: 0.7314 - val_accuracy: 0.8954\n",
      "Epoch 99/100\n",
      "390/390 [==============================] - 329s 842ms/step - loss: 0.2978 - accuracy: 0.9963 - val_loss: 0.7367 - val_accuracy: 0.8922\n",
      "Epoch 100/100\n",
      "390/390 [==============================] - 321s 824ms/step - loss: 0.2969 - accuracy: 0.9968 - val_loss: 0.7348 - val_accuracy: 0.8926\n",
      "\n",
      " Test accuracy\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9044    0.9180    0.9112      1000\n",
      "           1     0.9294    0.9610    0.9449      1000\n",
      "           2     0.8831    0.8460    0.8641      1000\n",
      "           3     0.7845    0.7790    0.7817      1000\n",
      "           4     0.8848    0.8760    0.8804      1000\n",
      "           5     0.8603    0.8250    0.8423      1000\n",
      "           6     0.8606    0.9510    0.9036      1000\n",
      "           7     0.9459    0.9090    0.9271      1000\n",
      "           8     0.9390    0.9390    0.9390      1000\n",
      "           9     0.9360    0.9220    0.9290      1000\n",
      "\n",
      "    accuracy                         0.8926     10000\n",
      "   macro avg     0.8928    0.8926    0.8923     10000\n",
      "weighted avg     0.8928    0.8926    0.8923     10000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2692aaa9808>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "numberOfEpochs = 100\n",
    "initialLearningRate = 0.1\n",
    "\n",
    "# load the training and testing data\n",
    "print(\"[INFO] loading CIFAR-10 data...\")\n",
    "((trainX, trainY), (testX, testY)) = cifar10.load_data()\n",
    "trainX = trainX.astype(\"float\")\n",
    "testX = testX.astype(\"float\")\n",
    "\n",
    "# apply mean subtraction to the data\n",
    "mean = np.mean(trainX, axis=0)\n",
    "trainX -= mean\n",
    "testX -= mean\n",
    "\n",
    "# convert the labels from integers to vectors\n",
    "lb = LabelBinarizer()\n",
    "trainY = lb.fit_transform(trainY)\n",
    "testY = lb.transform(testY)\n",
    "\n",
    "aug = ImageDataGenerator(width_shift_range = 0.1, height_shift_range = 0.1, horizontal_flip = True, fill_mode=\"nearest\")\n",
    "\n",
    "print(\"[INFO] compiling model...\")\n",
    "opt = SGD(lr = initialLearningRate)\n",
    "model = ResNet.build(32, 32, 3, 10, (9, 9, 9), (64, 64, 128, 256), reg=0.0005)\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = opt, metrics=['accuracy'])\n",
    "\n",
    "# print a model summary\n",
    "#print(model.summary())\n",
    "\n",
    "print(\"[INFO] training network...\")\n",
    "\n",
    "# code for a learning rate scheduler\n",
    "def polynomial_decay(epoch):\n",
    "    maxEpochs = numberOfEpochs\n",
    "    baseLearningRate = initialLearningRate\n",
    "    power = 1.0\n",
    "    \n",
    "    alpha = baseLearningRate * (1 - (epoch / float(numberOfEpochs))) ** power\n",
    "    \n",
    "    # return the learning rate\n",
    "    return alpha\n",
    "\n",
    "callbacks = [LearningRateScheduler(polynomial_decay)]\n",
    "\n",
    "H = model.fit(aug.flow(trainX, trainY, batch_size=128), validation_data=(testX, testY),\n",
    "              steps_per_epoch=len(trainX) // 128, epochs=numberOfEpochs, callbacks = callbacks, verbose=1)\n",
    "\n",
    "# print a classification report\n",
    "print('\\n Test accuracy')\n",
    "predictedY = model.predict(testX)\n",
    "predictedY = predictedY.argmax(axis=1)\n",
    "testY = testY.argmax(axis=1)\n",
    "print(classification_report(testY, predictedY, digits=4))\n",
    "\n",
    "# plot the training loss and accuracy\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(np.arange(0, numberOfEpochs), H.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(np.arange(0, numberOfEpochs), H.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(np.arange(0, numberOfEpochs), H.history[\"accuracy\"], label=\"train_acc\")\n",
    "plt.plot(np.arange(0, numberOfEpochs), H.history[\"val_accuracy\"], label=\"val_acc\")\n",
    "plt.title(\"Training Loss and Accuracy\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading CIFAR-10 data...\n",
      "[INFO] compiling model...\n",
      "[INFO] training network...\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 390 steps, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "390/390 [==============================] - 70s 180ms/step - loss: 2.1935 - accuracy: 0.3567 - val_loss: 2.0183 - val_accuracy: 0.4486\n",
      "Epoch 2/100\n",
      "390/390 [==============================] - 58s 149ms/step - loss: 1.8222 - accuracy: 0.5068 - val_loss: 1.8062 - val_accuracy: 0.5114\n",
      "Epoch 3/100\n",
      "390/390 [==============================] - 58s 148ms/step - loss: 1.6449 - accuracy: 0.5750 - val_loss: 1.8068 - val_accuracy: 0.5268\n",
      "Epoch 4/100\n",
      "390/390 [==============================] - 60s 153ms/step - loss: 1.5023 - accuracy: 0.6272 - val_loss: 1.4579 - val_accuracy: 0.6419\n",
      "Epoch 5/100\n",
      "390/390 [==============================] - 60s 154ms/step - loss: 1.3948 - accuracy: 0.6677 - val_loss: 1.4275 - val_accuracy: 0.6598\n",
      "Epoch 6/100\n",
      "390/390 [==============================] - 61s 158ms/step - loss: 1.3090 - accuracy: 0.6975 - val_loss: 1.3668 - val_accuracy: 0.6763\n",
      "Epoch 7/100\n",
      "390/390 [==============================] - 61s 156ms/step - loss: 1.2313 - accuracy: 0.7241 - val_loss: 1.3135 - val_accuracy: 0.7035\n",
      "Epoch 8/100\n",
      "390/390 [==============================] - 60s 153ms/step - loss: 1.1609 - accuracy: 0.7484 - val_loss: 1.3089 - val_accuracy: 0.7082\n",
      "Epoch 9/100\n",
      "390/390 [==============================] - 64s 164ms/step - loss: 1.1055 - accuracy: 0.7682 - val_loss: 1.1602 - val_accuracy: 0.7489\n",
      "Epoch 10/100\n",
      "390/390 [==============================] - 60s 154ms/step - loss: 1.0540 - accuracy: 0.7840 - val_loss: 1.2006 - val_accuracy: 0.7471\n",
      "Epoch 11/100\n",
      "390/390 [==============================] - 60s 155ms/step - loss: 1.0126 - accuracy: 0.7991 - val_loss: 1.2256 - val_accuracy: 0.7350\n",
      "Epoch 12/100\n",
      "390/390 [==============================] - 60s 154ms/step - loss: 0.9774 - accuracy: 0.8103 - val_loss: 1.0232 - val_accuracy: 0.8022\n",
      "Epoch 13/100\n",
      "390/390 [==============================] - 60s 154ms/step - loss: 0.9452 - accuracy: 0.8199 - val_loss: 1.0581 - val_accuracy: 0.7866\n",
      "Epoch 14/100\n",
      "390/390 [==============================] - 58s 150ms/step - loss: 0.9178 - accuracy: 0.8278 - val_loss: 0.9991 - val_accuracy: 0.8013\n",
      "Epoch 15/100\n",
      "390/390 [==============================] - 58s 149ms/step - loss: 0.8915 - accuracy: 0.8362 - val_loss: 1.0220 - val_accuracy: 0.7959\n",
      "Epoch 16/100\n",
      "390/390 [==============================] - 59s 152ms/step - loss: 0.8657 - accuracy: 0.8439 - val_loss: 1.0112 - val_accuracy: 0.8041\n",
      "Epoch 17/100\n",
      "390/390 [==============================] - 58s 148ms/step - loss: 0.8398 - accuracy: 0.8517 - val_loss: 1.0146 - val_accuracy: 0.8060\n",
      "Epoch 18/100\n",
      "390/390 [==============================] - 58s 149ms/step - loss: 0.8231 - accuracy: 0.8569 - val_loss: 1.0183 - val_accuracy: 0.7998\n",
      "Epoch 19/100\n",
      "390/390 [==============================] - 59s 150ms/step - loss: 0.8050 - accuracy: 0.8611 - val_loss: 1.0001 - val_accuracy: 0.8038\n",
      "Epoch 20/100\n",
      "390/390 [==============================] - 60s 154ms/step - loss: 0.7861 - accuracy: 0.8675 - val_loss: 0.9883 - val_accuracy: 0.8059\n",
      "Epoch 21/100\n",
      "390/390 [==============================] - 60s 155ms/step - loss: 0.7677 - accuracy: 0.8721 - val_loss: 0.9923 - val_accuracy: 0.8078\n",
      "Epoch 22/100\n",
      "390/390 [==============================] - 60s 153ms/step - loss: 0.7519 - accuracy: 0.8754 - val_loss: 0.9808 - val_accuracy: 0.8105\n",
      "Epoch 23/100\n",
      "390/390 [==============================] - 58s 149ms/step - loss: 0.7333 - accuracy: 0.8815 - val_loss: 1.0366 - val_accuracy: 0.7949\n",
      "Epoch 24/100\n",
      "390/390 [==============================] - 52s 132ms/step - loss: 0.7188 - accuracy: 0.8849 - val_loss: 0.9733 - val_accuracy: 0.8132\n",
      "Epoch 25/100\n",
      "390/390 [==============================] - 52s 132ms/step - loss: 0.7032 - accuracy: 0.8912 - val_loss: 0.9326 - val_accuracy: 0.8265\n",
      "Epoch 26/100\n",
      "390/390 [==============================] - 52s 132ms/step - loss: 0.6898 - accuracy: 0.8937 - val_loss: 0.8533 - val_accuracy: 0.8451\n",
      "Epoch 27/100\n",
      "390/390 [==============================] - 52s 132ms/step - loss: 0.6742 - accuracy: 0.8988 - val_loss: 0.9064 - val_accuracy: 0.8283\n",
      "Epoch 28/100\n",
      "390/390 [==============================] - 54s 138ms/step - loss: 0.6658 - accuracy: 0.9003 - val_loss: 0.8870 - val_accuracy: 0.8375\n",
      "Epoch 29/100\n",
      "390/390 [==============================] - 60s 155ms/step - loss: 0.6500 - accuracy: 0.9048 - val_loss: 0.9546 - val_accuracy: 0.8239\n",
      "Epoch 30/100\n",
      "390/390 [==============================] - 58s 149ms/step - loss: 0.6438 - accuracy: 0.9063 - val_loss: 0.8667 - val_accuracy: 0.8443\n",
      "Epoch 31/100\n",
      "390/390 [==============================] - 59s 152ms/step - loss: 0.6300 - accuracy: 0.9098 - val_loss: 0.8169 - val_accuracy: 0.8518\n",
      "Epoch 32/100\n",
      "390/390 [==============================] - 58s 150ms/step - loss: 0.6210 - accuracy: 0.9120 - val_loss: 0.8251 - val_accuracy: 0.8506\n",
      "Epoch 33/100\n",
      "390/390 [==============================] - 59s 150ms/step - loss: 0.6109 - accuracy: 0.9138 - val_loss: 0.7795 - val_accuracy: 0.8650\n",
      "Epoch 34/100\n",
      "390/390 [==============================] - 58s 150ms/step - loss: 0.5991 - accuracy: 0.9178 - val_loss: 0.8479 - val_accuracy: 0.8462\n",
      "Epoch 35/100\n",
      "390/390 [==============================] - 59s 152ms/step - loss: 0.5888 - accuracy: 0.9220 - val_loss: 0.8072 - val_accuracy: 0.8577\n",
      "Epoch 36/100\n",
      "390/390 [==============================] - 60s 154ms/step - loss: 0.5834 - accuracy: 0.9216 - val_loss: 0.8212 - val_accuracy: 0.8568\n",
      "Epoch 37/100\n",
      "390/390 [==============================] - 61s 155ms/step - loss: 0.5688 - accuracy: 0.9259 - val_loss: 0.7870 - val_accuracy: 0.8645\n",
      "Epoch 38/100\n",
      "390/390 [==============================] - 60s 155ms/step - loss: 0.5584 - accuracy: 0.9298 - val_loss: 0.8910 - val_accuracy: 0.8375\n",
      "Epoch 39/100\n",
      "390/390 [==============================] - 60s 155ms/step - loss: 0.5546 - accuracy: 0.9298 - val_loss: 0.8393 - val_accuracy: 0.8503\n",
      "Epoch 40/100\n",
      "390/390 [==============================] - 60s 154ms/step - loss: 0.5415 - accuracy: 0.9334 - val_loss: 0.8284 - val_accuracy: 0.8567\n",
      "Epoch 41/100\n",
      "390/390 [==============================] - 60s 154ms/step - loss: 0.5358 - accuracy: 0.9344 - val_loss: 0.7924 - val_accuracy: 0.8603\n",
      "Epoch 42/100\n",
      "390/390 [==============================] - 60s 154ms/step - loss: 0.5250 - accuracy: 0.9382 - val_loss: 0.8345 - val_accuracy: 0.8534\n",
      "Epoch 43/100\n",
      "390/390 [==============================] - 60s 155ms/step - loss: 0.5195 - accuracy: 0.9401 - val_loss: 0.8508 - val_accuracy: 0.8531\n",
      "Epoch 44/100\n",
      "390/390 [==============================] - 60s 155ms/step - loss: 0.5113 - accuracy: 0.9407 - val_loss: 0.7881 - val_accuracy: 0.8652\n",
      "Epoch 45/100\n",
      "390/390 [==============================] - 60s 155ms/step - loss: 0.5045 - accuracy: 0.9425 - val_loss: 0.8695 - val_accuracy: 0.8488\n",
      "Epoch 46/100\n",
      "390/390 [==============================] - 52s 132ms/step - loss: 0.4970 - accuracy: 0.9448 - val_loss: 0.8078 - val_accuracy: 0.8610\n",
      "Epoch 47/100\n",
      "390/390 [==============================] - 52s 132ms/step - loss: 0.4903 - accuracy: 0.9464 - val_loss: 0.8181 - val_accuracy: 0.8591\n",
      "Epoch 48/100\n",
      "390/390 [==============================] - 52s 132ms/step - loss: 0.4875 - accuracy: 0.9457 - val_loss: 0.7885 - val_accuracy: 0.8666\n",
      "Epoch 49/100\n",
      "390/390 [==============================] - 52s 133ms/step - loss: 0.4767 - accuracy: 0.9504 - val_loss: 0.7564 - val_accuracy: 0.8754\n",
      "Epoch 50/100\n",
      "390/390 [==============================] - 52s 132ms/step - loss: 0.4669 - accuracy: 0.9534 - val_loss: 0.7968 - val_accuracy: 0.8604\n",
      "Epoch 51/100\n",
      "390/390 [==============================] - 52s 132ms/step - loss: 0.4660 - accuracy: 0.9524 - val_loss: 0.7667 - val_accuracy: 0.8733\n",
      "Epoch 52/100\n",
      "390/390 [==============================] - 52s 133ms/step - loss: 0.4569 - accuracy: 0.9559 - val_loss: 0.8020 - val_accuracy: 0.8645\n",
      "Epoch 53/100\n",
      "390/390 [==============================] - 52s 132ms/step - loss: 0.4506 - accuracy: 0.9569 - val_loss: 0.8040 - val_accuracy: 0.8582\n",
      "Epoch 54/100\n",
      "390/390 [==============================] - 52s 133ms/step - loss: 0.4462 - accuracy: 0.9581 - val_loss: 0.7723 - val_accuracy: 0.8707\n",
      "Epoch 55/100\n",
      "390/390 [==============================] - 52s 133ms/step - loss: 0.4393 - accuracy: 0.9595 - val_loss: 0.7627 - val_accuracy: 0.8733\n",
      "Epoch 56/100\n",
      "390/390 [==============================] - 52s 133ms/step - loss: 0.4322 - accuracy: 0.9614 - val_loss: 0.7953 - val_accuracy: 0.8621\n",
      "Epoch 57/100\n",
      "390/390 [==============================] - 52s 132ms/step - loss: 0.4281 - accuracy: 0.9622 - val_loss: 0.7826 - val_accuracy: 0.8672\n",
      "Epoch 58/100\n",
      "390/390 [==============================] - 52s 133ms/step - loss: 0.4247 - accuracy: 0.9630 - val_loss: 0.7692 - val_accuracy: 0.8738\n",
      "Epoch 59/100\n",
      "390/390 [==============================] - 52s 132ms/step - loss: 0.4161 - accuracy: 0.9664 - val_loss: 0.7478 - val_accuracy: 0.8809\n",
      "Epoch 60/100\n",
      "390/390 [==============================] - 52s 132ms/step - loss: 0.4113 - accuracy: 0.9669 - val_loss: 0.7391 - val_accuracy: 0.8806\n",
      "Epoch 61/100\n",
      "390/390 [==============================] - 52s 133ms/step - loss: 0.4077 - accuracy: 0.9673 - val_loss: 0.7476 - val_accuracy: 0.8769\n",
      "Epoch 62/100\n",
      "390/390 [==============================] - 52s 133ms/step - loss: 0.4003 - accuracy: 0.9700 - val_loss: 0.7471 - val_accuracy: 0.8820\n",
      "Epoch 63/100\n",
      "390/390 [==============================] - 52s 133ms/step - loss: 0.3972 - accuracy: 0.9696 - val_loss: 0.7753 - val_accuracy: 0.8737\n",
      "Epoch 64/100\n",
      "390/390 [==============================] - 52s 132ms/step - loss: 0.3896 - accuracy: 0.9724 - val_loss: 0.7747 - val_accuracy: 0.8758\n",
      "Epoch 65/100\n",
      "390/390 [==============================] - 56s 145ms/step - loss: 0.3854 - accuracy: 0.9752 - val_loss: 0.7551 - val_accuracy: 0.8809\n",
      "Epoch 66/100\n",
      "390/390 [==============================] - 59s 150ms/step - loss: 0.3823 - accuracy: 0.9738 - val_loss: 0.7987 - val_accuracy: 0.8757\n",
      "Epoch 67/100\n",
      "390/390 [==============================] - 58s 149ms/step - loss: 0.3775 - accuracy: 0.9761 - val_loss: 0.7630 - val_accuracy: 0.8792\n",
      "Epoch 68/100\n",
      "390/390 [==============================] - 61s 156ms/step - loss: 0.3701 - accuracy: 0.9779 - val_loss: 0.7594 - val_accuracy: 0.8844\n",
      "Epoch 69/100\n",
      "390/390 [==============================] - 61s 155ms/step - loss: 0.3660 - accuracy: 0.9787 - val_loss: 0.7461 - val_accuracy: 0.8823\n",
      "Epoch 70/100\n",
      "390/390 [==============================] - 60s 155ms/step - loss: 0.3659 - accuracy: 0.9790 - val_loss: 0.7718 - val_accuracy: 0.8794\n",
      "Epoch 71/100\n",
      "390/390 [==============================] - 60s 155ms/step - loss: 0.3622 - accuracy: 0.9797 - val_loss: 0.7458 - val_accuracy: 0.8843\n",
      "Epoch 72/100\n",
      "390/390 [==============================] - 61s 155ms/step - loss: 0.3573 - accuracy: 0.9809 - val_loss: 0.7590 - val_accuracy: 0.8806\n",
      "Epoch 73/100\n",
      "390/390 [==============================] - 60s 154ms/step - loss: 0.3542 - accuracy: 0.9820 - val_loss: 0.8144 - val_accuracy: 0.8691\n",
      "Epoch 74/100\n",
      "390/390 [==============================] - 60s 153ms/step - loss: 0.3493 - accuracy: 0.9833 - val_loss: 0.7318 - val_accuracy: 0.8890\n",
      "Epoch 75/100\n",
      "390/390 [==============================] - 61s 155ms/step - loss: 0.3454 - accuracy: 0.9837 - val_loss: 0.7315 - val_accuracy: 0.8892\n",
      "Epoch 76/100\n",
      "390/390 [==============================] - 61s 156ms/step - loss: 0.3425 - accuracy: 0.9851 - val_loss: 0.7435 - val_accuracy: 0.8868\n",
      "Epoch 77/100\n",
      "390/390 [==============================] - 61s 156ms/step - loss: 0.3389 - accuracy: 0.9857 - val_loss: 0.7305 - val_accuracy: 0.8895\n",
      "Epoch 78/100\n",
      "390/390 [==============================] - 59s 150ms/step - loss: 0.3388 - accuracy: 0.9857 - val_loss: 0.7664 - val_accuracy: 0.8856\n",
      "Epoch 79/100\n",
      "390/390 [==============================] - 58s 148ms/step - loss: 0.3327 - accuracy: 0.9874 - val_loss: 0.7573 - val_accuracy: 0.8854\n",
      "Epoch 80/100\n",
      "390/390 [==============================] - 59s 152ms/step - loss: 0.3300 - accuracy: 0.9884 - val_loss: 0.7251 - val_accuracy: 0.8914\n",
      "Epoch 81/100\n",
      "390/390 [==============================] - 58s 150ms/step - loss: 0.3255 - accuracy: 0.9897 - val_loss: 0.7342 - val_accuracy: 0.8889\n",
      "Epoch 82/100\n",
      "390/390 [==============================] - 58s 150ms/step - loss: 0.3224 - accuracy: 0.9901 - val_loss: 0.7272 - val_accuracy: 0.8922\n",
      "Epoch 83/100\n",
      "390/390 [==============================] - 58s 149ms/step - loss: 0.3193 - accuracy: 0.9913 - val_loss: 0.7209 - val_accuracy: 0.8935\n",
      "Epoch 84/100\n",
      "390/390 [==============================] - 52s 132ms/step - loss: 0.3192 - accuracy: 0.9912 - val_loss: 0.7327 - val_accuracy: 0.8903\n",
      "Epoch 85/100\n",
      "390/390 [==============================] - 52s 133ms/step - loss: 0.3161 - accuracy: 0.9922 - val_loss: 0.7317 - val_accuracy: 0.8918\n",
      "Epoch 86/100\n",
      "390/390 [==============================] - 52s 133ms/step - loss: 0.3143 - accuracy: 0.9926 - val_loss: 0.7420 - val_accuracy: 0.8898\n",
      "Epoch 87/100\n",
      "390/390 [==============================] - 52s 132ms/step - loss: 0.3126 - accuracy: 0.9923 - val_loss: 0.7375 - val_accuracy: 0.8921\n",
      "Epoch 88/100\n",
      "390/390 [==============================] - 56s 142ms/step - loss: 0.3102 - accuracy: 0.9934 - val_loss: 0.7197 - val_accuracy: 0.8953\n",
      "Epoch 89/100\n",
      "390/390 [==============================] - 62s 158ms/step - loss: 0.3078 - accuracy: 0.9936 - val_loss: 0.7304 - val_accuracy: 0.8958\n",
      "Epoch 90/100\n",
      "390/390 [==============================] - 60s 153ms/step - loss: 0.3067 - accuracy: 0.9938 - val_loss: 0.7199 - val_accuracy: 0.8956\n",
      "Epoch 91/100\n",
      "390/390 [==============================] - 60s 154ms/step - loss: 0.3050 - accuracy: 0.9945 - val_loss: 0.7357 - val_accuracy: 0.8924\n",
      "Epoch 92/100\n",
      "390/390 [==============================] - 61s 156ms/step - loss: 0.3032 - accuracy: 0.9953 - val_loss: 0.7303 - val_accuracy: 0.8942\n",
      "Epoch 93/100\n",
      "390/390 [==============================] - 61s 156ms/step - loss: 0.3019 - accuracy: 0.9951 - val_loss: 0.7137 - val_accuracy: 0.8978\n",
      "Epoch 94/100\n",
      "390/390 [==============================] - 58s 150ms/step - loss: 0.3011 - accuracy: 0.9953 - val_loss: 0.7156 - val_accuracy: 0.8980\n",
      "Epoch 95/100\n",
      "390/390 [==============================] - 59s 151ms/step - loss: 0.3004 - accuracy: 0.9956 - val_loss: 0.7239 - val_accuracy: 0.8972\n",
      "Epoch 96/100\n",
      "390/390 [==============================] - 59s 150ms/step - loss: 0.2995 - accuracy: 0.9959 - val_loss: 0.7214 - val_accuracy: 0.8959\n",
      "Epoch 97/100\n",
      "390/390 [==============================] - 59s 151ms/step - loss: 0.2979 - accuracy: 0.9965 - val_loss: 0.7184 - val_accuracy: 0.8978\n",
      "Epoch 98/100\n",
      "390/390 [==============================] - 58s 149ms/step - loss: 0.2978 - accuracy: 0.9966 - val_loss: 0.7150 - val_accuracy: 0.8973\n",
      "Epoch 99/100\n",
      "390/390 [==============================] - 52s 132ms/step - loss: 0.2956 - accuracy: 0.9975 - val_loss: 0.7200 - val_accuracy: 0.8969\n",
      "Epoch 100/100\n",
      "390/390 [==============================] - 52s 133ms/step - loss: 0.2957 - accuracy: 0.9971 - val_loss: 0.7183 - val_accuracy: 0.8965\n",
      "\n",
      " Test accuracy\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9033    0.9060    0.9046      1000\n",
      "           1     0.9333    0.9650    0.9489      1000\n",
      "           2     0.8742    0.8550    0.8645      1000\n",
      "           3     0.8106    0.7790    0.7945      1000\n",
      "           4     0.9051    0.8580    0.8809      1000\n",
      "           5     0.8657    0.8380    0.8516      1000\n",
      "           6     0.8870    0.9500    0.9174      1000\n",
      "           7     0.9200    0.9320    0.9260      1000\n",
      "           8     0.9427    0.9370    0.9398      1000\n",
      "           9     0.9175    0.9450    0.9310      1000\n",
      "\n",
      "    accuracy                         0.8965     10000\n",
      "   macro avg     0.8959    0.8965    0.8959     10000\n",
      "weighted avg     0.8959    0.8965    0.8959     10000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1942299b7c8>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "numberOfEpochs = 100\n",
    "initialLearningRate = 0.1\n",
    "\n",
    "# load the training and testing data\n",
    "print(\"[INFO] loading CIFAR-10 data...\")\n",
    "((trainX, trainY), (testX, testY)) = cifar10.load_data()\n",
    "trainX = trainX.astype(\"float\")\n",
    "testX = testX.astype(\"float\")\n",
    "\n",
    "# apply mean subtraction to the data\n",
    "mean = np.mean(trainX, axis=0)\n",
    "trainX -= mean\n",
    "testX -= mean\n",
    "\n",
    "# convert the labels from integers to vectors\n",
    "lb = LabelBinarizer()\n",
    "trainY = lb.fit_transform(trainY)\n",
    "testY = lb.transform(testY)\n",
    "\n",
    "aug = ImageDataGenerator(width_shift_range = 0.1, height_shift_range = 0.1, horizontal_flip = True, fill_mode=\"nearest\")\n",
    "\n",
    "print(\"[INFO] compiling model...\")\n",
    "opt = SGD(lr = initialLearningRate)\n",
    "model = ResNet.build(32, 32, 3, 10, (9, 9, 9), (64, 64, 128, 256), reg=0.0005)\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = opt, metrics=['accuracy'])\n",
    "\n",
    "# print a model summary\n",
    "#print(model.summary())\n",
    "\n",
    "print(\"[INFO] training network...\")\n",
    "\n",
    "# code for a learning rate scheduler\n",
    "def polynomial_decay(epoch):\n",
    "    maxEpochs = numberOfEpochs\n",
    "    baseLearningRate = initialLearningRate\n",
    "    power = 1.0\n",
    "    \n",
    "    alpha = baseLearningRate * (1 - (epoch / float(numberOfEpochs))) ** power\n",
    "    \n",
    "    # return the learning rate\n",
    "    return alpha\n",
    "\n",
    "callbacks = [LearningRateScheduler(polynomial_decay)]\n",
    "\n",
    "H = model.fit(aug.flow(trainX, trainY, batch_size=128), validation_data=(testX, testY),\n",
    "              steps_per_epoch=len(trainX) // 128, epochs=numberOfEpochs, callbacks = callbacks, verbose=1)\n",
    "\n",
    "# print a classification report\n",
    "print('\\n Test accuracy')\n",
    "predictedY = model.predict(testX)\n",
    "predictedY = predictedY.argmax(axis=1)\n",
    "testY = testY.argmax(axis=1)\n",
    "print(classification_report(testY, predictedY, digits=4))\n",
    "\n",
    "# plot the training loss and accuracy\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(np.arange(0, numberOfEpochs), H.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(np.arange(0, numberOfEpochs), H.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(np.arange(0, numberOfEpochs), H.history[\"accuracy\"], label=\"train_acc\")\n",
    "plt.plot(np.arange(0, numberOfEpochs), H.history[\"val_accuracy\"], label=\"val_acc\")\n",
    "plt.title(\"Training Loss and Accuracy\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results are good but a little underwhelming here--according to Identity Mappings in Deep Residual Networks (He et. al., 2016, https://arxiv.org/abs/1603.05027), a similar approach can reach about 94% accuracy."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
